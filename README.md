# Spiking Neural Networks for Event-Based Regression

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.12+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

<p align="center">
  <img src="docs/images/architecture_overview.png" alt="Architecture Overview" width="800"/>
</p>

Official implementation of **"Spiking Neural Networks for Event-Based Regression: Analysis of Neuron Dynamics and Normalization Strategies"**.

Event-based cameras provide asynchronous visual measurements with microsecond temporal resolution. This repository explores deep Spiking Neural Networks (SNNs) for continuous-valued regression on event streams, analyzing the fundamental design trade-offs between neuron dynamics, normalization mechanisms, and residual architectures.

---

## ğŸ¯ Key Contributions

- **Gradient-level analysis** of Leaky (LIF) vs Non-leaky (IF) output neurons for regression
- **Normalization strategies comparison**: BatchNorm, RMSNorm, and Fixed Scaling  
- **Architectural blocks**: Plain, Spiking ResNet, and SEW-ResNet for deep SNNs
- **Experimental validation** on rotary inverted pendulum control and event-based ego-motion estimation

---

## ğŸ“Š Dataset Examples

### Rotary Inverted Pendulum
Event camera captures the angular motion of an inverted pendulum from a top-view perspective.

<p align="center">
  <img src="docs/videos/pendulum_example.gif" alt="Pendulum Dataset" width="400"/>
  <br>
  <em>Sample sequence showing ON events (blue) and OFF events (red)</em>
</p>

**Event Statistics:**
- Resolution: 346Ã—260 pixels
- Integration window: Î”t = 30ms
- Average events per frame: ~1,500-3,000
- Dataset size: 50,000 timesteps

### Event-Based Ego-Motion (IMU)
DAVIS346 camera moving along roll and yaw axes, with ground truth from onboard IMU.

<p align="center">
  <img src="docs/videos/imu_example.gif" alt="IMU Dataset" width="400"/>
  <br>
  <em>Camera motion with higher temporal resolution (Î”t = 10ms)</em>
</p>

**Event Statistics:**
- Resolution: 346Ã—260 pixels
- Integration window: Î”t = 10ms
- Average events per frame: ~2,000-5,000
- Dataset size: Multiple sequences totaling >100k timesteps

---

## ğŸ—ï¸ Architecture

### Network Components

The SNN consists of:
1. **Convolutional Blocks** with Leaky Integrate-and-Fire (LIF) neurons
2. **Normalization Layers** (BatchNorm / RMSNorm / Fixed Scaling)
3. **Residual Connections** (Plain / Spiking ResNet / SEW-ResNet)
4. **Regression Head** with high-tau LIF neuron (Ï„=20) for stable output

<p align="center">
  <img src="docs/images/residual_blocks.png" alt="Residual Block Types" width="700"/>
</p>

### Neuron Dynamics

**Hidden Layers (LIF):**
```
H[t] = (1 - 1/Ï„)V[t-1] + (1/Ï„)I[t]
S[t] = Î˜(H[t] - V_th)
V[t] = H[t] - S[t]Â·V_th
```

**Output Layer (High-tau LIF):**
```
H[t] = (1 - 1/Ï„_final)V[t-1] + (1/Ï„_final)I[t]
y[t] = H[t]  (membrane potential as continuous prediction)
```

---

## ğŸ“ˆ Results

### Experiment 1: Rotary Inverted Pendulum

**Angle Estimation Error (MAE in degrees):**

| Architecture | BatchNorm | RMSNorm | Fixed Scaling |
|--------------|-----------|---------|---------------|
| **SEW**      | 1.698Â°    | **1.651Â°** | 1.734Â°      |
| **Spiking**  | 1.907Â°    | **1.632Â°** | 2.153Â°      |
| **Plain**    | 2.547Â°    | 1.709Â°  | 2.341Â°        |

âœ¨ **Best result:** Spiking ResNet + RMSNorm = **1.632Â° MAE**

<p align="center">
  <img src="docs/images/pendulum_predictions.png" alt="Pendulum Predictions" width="800"/>
  <br>
  <em>Model predictions vs ground truth on test sequence</em>
</p>

### Impact of Output Layer Time Constant

<p align="center">
  <img src="docs/images/tau_comparison.png" alt="Tau Comparison" width="700"/>
  <br>
  <em>Comparison of Ï„=2.0 (noisy) vs Ï„=20.0 (stable) predictions</em>
</p>

### Experiment 2: Event-Based Ego-Motion Estimation

**Roll Angle Estimation:**

<p align="center">
  <img src="docs/images/imu_predictions.png" alt="IMU Predictions" width="800"/>
  <br>
  <em>Visual odometry from event stream (10ms windows)</em>
</p>

---

## ğŸ”¬ Normalization Analysis

### What Are Normalization Layers Doing?

Our experiments reveal that **normalization primarily acts as gain control** rather than statistical re-centering:

<p align="center">
  <img src="docs/images/normalization_analysis.png" alt="Normalization Analysis" width="800"/>
</p>

**Key Findings:**
1. Learnable parameters (Î³, Î², Î±) remain close to initialization
2. Effective scaling factors converge to similar values across BN/RMS/MUL
3. **Purpose**: Amplify membrane potentials to sustain spiking activity
4. Without sufficient scaling â†’ vanishing spikes â†’ gradient collapse

### Gradient Dynamics: LIF vs IF Output

For regression outputs, we analyze gradient growth over time T:

**LIF Output (with leak Î² < 1):**
```
âˆ‚L/âˆ‚W = (1-Î²) Î£_t âˆ‚L[t]/âˆ‚V[t] (Î£_s Î²^(t-s) X[s])
â†’ Exponential decay prevents gradient explosion
```

**IF Output (no leak):**
```
âˆ‚L/âˆ‚W = Î£_t âˆ‚L[t]/âˆ‚V[t] (Î£_s X[s])
â†’ Quadratic growth O(TÂ²) causes instability
```

**Solution:** Use high-tau LIF (Ï„=20) to approximate IF while maintaining training stability.

---

## ğŸš€ Getting Started

### Installation

```bash
# Clone repository
git clone https://github.com/your-username/snn-event-regression.git
cd snn-event-regression

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Requirements

- Python 3.8+
- PyTorch 1.12+
- SpikingJelly 0.0.0.0.14+
- NumPy, Matplotlib, OpenCV
- Tonic (for event processing)
- Weights & Biases (optional, for logging)

### Quick Start

**1. Train on Pendulum Dataset:**
```bash
python main.py
```

**2. Configure Experiment:**
Edit [main.py](main.py#L40):
```python
experiment = "IMU"           # Options: "pendulum", "IMU"
block_type = 'SEW'           # Options: 'SEW', 'plain', 'spiking'
norm_type = 'RMS'            # Options: 'BN', 'RMS', 'MUL', None
train_model = True           # Set False to load pretrained weights
```

**3. Monitor Training:**
```python
use_wandb = True             # Enable Weights & Biases logging
monitor_mode = "both"        # Options: "none", "spikes", "norm", "both"
```

---

## ğŸ“ Project Structure

```
snn-event-regression/
â”œâ”€â”€ main.py                      # Main training/testing script
â”œâ”€â”€ data/                        # Dataset directory
â”‚   â”œâ”€â”€ imu_events_large.aedat4
â”‚   â””â”€â”€ pendulum_events.aedat4
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train.py                 # Training loop with TBPTT
â”‚   â”œâ”€â”€ test.py                  # Testing and evaluation
â”‚   â”œâ”€â”€ utils.py                 # Visualization and utilities
â”‚   â”œâ”€â”€ Dataset/
â”‚   â”‚   â”œâ”€â”€ dataloaders.py       # Sequential data loading
â”‚   â”‚   â”œâ”€â”€ datasets.py          # Event stream datasets
â”‚   â”‚   â””â”€â”€ read_file.py         # AEDAT4 file parsing
â”‚   â””â”€â”€ Network/
â”‚       â”œâ”€â”€ SNN.py               # Main network architecture
â”‚       â”œâ”€â”€ blocks.py            # Residual blocks (Plain/Spiking/SEW)
â”‚       â””â”€â”€ norm.py              # Normalization layers (BN/RMS/MUL)
â”œâ”€â”€ models/                      # Saved checkpoints
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for analysis
â””â”€â”€ docs/                        # Documentation and figures
```

---

## âš™ï¸ Training Details

### Truncated Backpropagation Through Time (TBPTT)

Event streams are extremely long, making standard BPTT impractical. We use TBPTT:

```python
K = 10  # Backprop every 10 timesteps
for t in range(0, T, K):
    forward_pass(t, t+K)
    backward_pass()      # Gradients truncated at K steps
    model.detach()       # Detach hidden states
```

### Hyperparameters

| Parameter | Pendulum | IMU | Description |
|-----------|----------|-----|-------------|
| Ï„ (hidden) | 2.0 | 2.0 | Time constant for LIF neurons |
| Ï„ (output) | 20.0 | 20.0 | High-tau for stable regression |
| K (TBPTT) | 10 | 10 | Truncation window |
| Transient | 200 | 0 | Warmup timesteps to skip |
| Batch Size | 4 | 4 | Sequences per batch |
| Seq Length | 2000 | 2000 | Timesteps per sequence |
| Optimizer | SGD | SGD | With momentum 0.9 |
| LR | 1e-2 | 1e-2 | With ReduceLROnPlateau |
| Epochs | 20 | 30 | Early stopping enabled |

### Surrogate Gradient

Non-differentiable spike function requires surrogate:
```python
surrogate_function = surrogate.ATan()  # arctan(Î±x)
```

---

## ğŸ“Š Visualization & Monitoring

### Spike Activity Monitoring

Track spiking activity through the network:

```python
monitor_mode = "spikes"  # Record spike counts per layer
```

<p align="center">
  <img src="docs/images/spike_activity.png" alt="Spike Activity" width="700"/>
  <br>
  <em>Layer-wise spike rates showing effect of normalization</em>
</p>

### Normalization Parameter Evolution

Monitor how Î³, Î², Î± evolve during training:

```python
monitor_mode = "norm"  # Track normalization parameters
```

<p align="center">
  <img src="docs/images/norm_params.png" alt="Normalization Parameters" width="700"/>
  <br>
  <em>Parameters remain nearly constant, confirming fixed-gain behavior</em>
</p>

---

## ğŸ”§ Advanced Usage

### Custom Dataset

```python
from src.Dataset import read_pendulum_file

events, labels = read_pendulum_file(
    aedat_path="data/custom.aedat4",
    csv_path="data/custom_labels.csv",
    time_window=30000  # 30ms integration
)
```

### Custom Architecture

```python
from src.Network import SNN_Net

model = SNN_Net(
    tau=2.0,              # Hidden neuron time constant
    final_tau=20.0,       # Output neuron time constant
    layer_list=custom_layers,
    hidden=512,           # FC layer size
    norm_type="RMS",      # Normalization type
    init_scale=6.0        # Scaling factor for MUL
)
```

### Custom Block Configuration

```python
layer_list_custom = [
    {"channels": 16, "mid_channels": 16, "num_blocks": 1, "block_type": "sew",
     "up_kernel_size": 3, "stride_1": 2, "stride_2": 1, "k_pool": (2,2)},
    {"channels": 32, "mid_channels": 32, "num_blocks": 2, "block_type": "sew",
     "up_kernel_size": 1, "stride_1": 1, "stride_2": 1, "k_pool": (2,2)},
]
```

---

## ğŸ“ Citation

If you use this code in your research, please cite:

```bibtex
@inproceedings{anonymous2026snn,
  title={Spiking Neural Networks for Event-Based Regression: Analysis of Neuron Dynamics and Normalization Strategies},
  author={Anonymous},
  booktitle={International Joint Conference on Neural Networks (IJCNN)},
  year={2026},
  note={Under review}
}
```

---

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **SpikingJelly** framework for SNN implementation
- **Tonic** library for event-based data processing
- Event datasets collected using DAVIS346 camera
- Inspired by [StereoSpike](https://github.com/urancon/StereoSpike) normalization strategies

---

## ğŸ“§ Contact

For questions or collaboration:
- **Paper**: [Anonymous 4open.science link](https://anonymous.4open.science/r/snn-event-regression/)
- **Issues**: [GitHub Issues](https://github.com/your-username/snn-event-regression/issues)

---

<p align="center">
  <em>Event-driven vision meets neuromorphic computing ğŸ§ âš¡</em>
</p>

