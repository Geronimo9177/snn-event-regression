{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b85ca1ef",
   "metadata": {
    "id": "b85ca1ef"
   },
   "source": [
    "# Spiking Neural Network for Event-Based Regression\n",
    "\n",
    "## Overview\n",
    "This notebook implements a Spiking Neural Network (SNN) to regress the camera roll angle from event camera streams. The model consumes asynchronous events recorded with a DAVIS346 and learns to predict the camera orientation while the camera moves.\n",
    "\n",
    "### Key Features\n",
    "- **Multiple architectures**: Supports Plain, Spiking ResNet, and SEW (Spiking Element-Wise) blocks\n",
    "- **Flexible normalization**: Batch Normalization, RMS Normalization, or learnable scaling\n",
    "- **TBPTT training**: Truncated Backpropagation Through Time for efficient temporal learning\n",
    "\n",
    "### Requirements\n",
    "- GPU with CUDA support (recommended)\n",
    "- Event camera data in AEDAT4 format with synchronized IMU\n",
    "\n",
    "### Citation\n",
    "If you use this code in your research, please cite our paper:\n",
    "```\n",
    "[Your paper citation here]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfa9613",
   "metadata": {},
   "source": [
    "## Library Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a934b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas dv_processing opencv-python tonic spikingjelly wandb aedat ahrs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e819d7c",
   "metadata": {
    "id": "5e819d7c"
   },
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9240739",
   "metadata": {
    "id": "b9240739"
   },
   "outputs": [],
   "source": [
    "# Event camera data processing libraries\n",
    "import dv_processing as dv  \n",
    "import numpy as np  \n",
    "import cv2 as cv \n",
    "import torch.nn.functional as F  \n",
    "import pandas as pd  \n",
    "from scipy.interpolate import interp1d\n",
    "from ahrs.filters import Madgwick\n",
    "\n",
    "# Event camera data transformation library\n",
    "import tonic \n",
    "from tonic import transforms, MemoryCachedDataset \n",
    "\n",
    "# PyTorch deep learning framework\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import Tensor\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "# SpikingJelly: SNN framework for PyTorch\n",
    "from spikingjelly.activation_based import neuron, surrogate, functional\n",
    "\n",
    "# Progress tracking\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Experiment tracking and logging\n",
    "import wandb\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Random seed control\n",
    "import random\n",
    "\n",
    "# File system operations\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6217e4",
   "metadata": {
    "id": "ac6217e4"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Reproducibility: Set random seeds for all libraries\n",
    "# ============================================================================\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# Python random\n",
    "random.seed(SEED)\n",
    "\n",
    "# NumPy\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# PyTorch\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8093afd4",
   "metadata": {
    "id": "8093afd4"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41fb8c0",
   "metadata": {
    "id": "d41fb8c0"
   },
   "outputs": [],
   "source": [
    "def visualize_sequence_from_trainloader(trainloader, n_sequences=5, playback_fps=10, scale=1):\n",
    "    \"\"\"\n",
    "    Visualize temporal sequences from the training dataloader.\n",
    "    \"\"\"\n",
    "\n",
    "    for seq_idx, (frames_batch, labels_batch) in enumerate(trainloader):\n",
    "        if seq_idx >= n_sequences:\n",
    "            break\n",
    "\n",
    "        # frames_batch: [T, B, C, H, W]\n",
    "        # labels_batch: [T, B]\n",
    "        T, B, C, H, W = frames_batch.shape\n",
    "\n",
    "        print(f\"\\n=== Sequence {seq_idx+1}/{n_sequences} ===\")\n",
    "        print(f\"Batch shape: {frames_batch.shape}, Labels shape: {labels_batch.shape}\")\n",
    "\n",
    "        # Visualize only the first element of the batch\n",
    "        batch_item = 0\n",
    "\n",
    "        for t in range(T):\n",
    "            # Extract frame at time t for the first batch item\n",
    "            # frame: [C, H, W] where C=2 (ON/OFF polarities)\n",
    "            frame = frames_batch[t, batch_item].cpu().numpy()  # [2, H, W]\n",
    "            angle = labels_batch[t, batch_item].item()\n",
    "\n",
    "            # Create RGB visualization (white background)\n",
    "            # Channel 0 = ON events (positive), Channel 1 = OFF events (negative)\n",
    "            events_img = np.ones((H, W, 3), dtype=np.uint8) * 255\n",
    "\n",
    "            # ON events in dark blue\n",
    "            on_events = frame[0] > 0\n",
    "            events_img[on_events] = [0, 0, 200]\n",
    "\n",
    "            # OFF events in dark red\n",
    "            off_events = frame[1] > 0\n",
    "            events_img[off_events] = [200, 0, 0]\n",
    "\n",
    "            # Scale image\n",
    "            events_resized = cv.resize(events_img, (W*scale, H*scale),\n",
    "                                      interpolation=cv.INTER_NEAREST)\n",
    "\n",
    "            # Overlay text information\n",
    "            info_text = [\n",
    "                f\"Seq: {seq_idx+1}/{n_sequences}  Time: {t+1}/{T}\",\n",
    "                f\"Target angle: {np.rad2deg(angle):.2f} deg\",\n",
    "                f\"Batch item: {batch_item+1}/{B}\"\n",
    "            ]\n",
    "\n",
    "            y_offset = 30\n",
    "            for text in info_text:\n",
    "                cv.putText(events_resized, text,\n",
    "                          (10, y_offset), cv.FONT_HERSHEY_SIMPLEX,\n",
    "                          0.6, (0, 0, 0), 2)\n",
    "                y_offset += 25\n",
    "\n",
    "            # Display frame\n",
    "            cv.imshow(\"Trainloader Sequence Visualization\", events_resized)\n",
    "\n",
    "            # Wait for key press (controls playback speed)\n",
    "            key = cv.waitKey(int(1000 / playback_fps))\n",
    "            if key == 27:  # ESC key to exit\n",
    "                cv.destroyAllWindows()\n",
    "                return\n",
    "            elif key == ord('n'):  # 'n' key to skip to next sequence\n",
    "                break\n",
    "\n",
    "    cv.destroyAllWindows()\n",
    "    print(\"\\nVisualization completed!\")\n",
    "\n",
    "# ============================================================================\n",
    "# Normalization and Denormalization Functions\n",
    "# ============================================================================\n",
    "def normalize_targets(targets):\n",
    "    \"\"\"\n",
    "    Normalize targets from [-pi, 0] radians to [0, 1] range.\n",
    "    \"\"\"\n",
    "    return - targets / np.pi\n",
    "\n",
    "\n",
    "def denormalize_targets(normalized_targets):\n",
    "    \"\"\"\n",
    "    Convert normalized targets [0, 1] back to degrees [-180, 0].\n",
    "    \"\"\"\n",
    "    return - normalized_targets * 180"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170f289b",
   "metadata": {
    "id": "170f289b"
   },
   "source": [
    "## Data Loading and Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c383d0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54c0563",
   "metadata": {
    "id": "b54c0563"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# File Paths and Data Loading\n",
    "# ============================================================================\n",
    "# Load event camera data from AEDAT4 file format\n",
    "\n",
    "FILE_PATH = \"/content/drive/MyDrive/snn_event_regression_data/imu_events.aedat4\"\n",
    "\n",
    "# Load event data using Tonic library\n",
    "events = tonic.io.read_aedat4(FILE_PATH)\n",
    "\n",
    "# Load IMU data using dv_processing library\n",
    "reader = dv.io.MonoCameraRecording(FILE_PATH)\n",
    "\n",
    "timestamps = []\n",
    "acc = []\n",
    "gyro = []\n",
    "\n",
    "while reader.isRunning():\n",
    "    imu_batch = reader.getNextImuBatch()\n",
    "    if imu_batch is not None and len(imu_batch) > 0:\n",
    "        for m in imu_batch:\n",
    "            timestamps.append(m.timestamp)\n",
    "            acc.append([m.accelerometerX, m.accelerometerY, m.accelerometerZ])\n",
    "            gyro.append([m.gyroscopeX, m.gyroscopeY, m.gyroscopeZ])\n",
    "\n",
    "timestamps = np.array(timestamps)\n",
    "acc = np.array(acc)\n",
    "gyro = np.array(gyro)\n",
    "\n",
    "# Convert gyroscope from degrees to radians\n",
    "gyro = np.deg2rad(gyro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7cf073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Madgwick Filter - Orientation Estimation from Inertial Measurement Unit (IMU)\n",
    "# ============================================================================\n",
    "# Automatic initialization\n",
    "# Initialize Madgwick filter with first IMU sample to compute initial quaternion\n",
    "\n",
    "init_madgwick = Madgwick(acc=acc[:1], gyr=gyro[:1], frequency=1000)\n",
    "\n",
    "# Extract the computed initial quaternion\n",
    "q = init_madgwick.Q[0]\n",
    "\n",
    "madgwick = Madgwick(gain=0.033)  # IMU-only, recommended value\n",
    "\n",
    "Q = [q]\n",
    "\n",
    "for k in range(1, len(acc)):\n",
    "    # Real timestep in seconds\n",
    "    dt = (timestamps[k] - timestamps[k-1]) * 1e-6\n",
    "    madgwick.Dt = dt\n",
    "\n",
    "    q = madgwick.updateIMU(q, gyr=gyro[k], acc=acc[k])\n",
    "    Q.append(np.array(q))\n",
    "\n",
    "Q = np.array(Q)\n",
    "\n",
    "# Extract quaternion components (w, x, y, z)\n",
    "w = Q[:, 0]\n",
    "x = Q[:, 1]\n",
    "y = Q[:, 2]\n",
    "z = Q[:, 3]\n",
    "\n",
    "# Calculate Roll (Rotation around X-axis)\n",
    "sinr_cosp = 2 * (w * x + y * z)\n",
    "cosr_cosp = 1 - 2 * (x * x + y * y)\n",
    "roll = np.arctan2(sinr_cosp, cosr_cosp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9cad25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7f9cad25",
    "outputId": "fc0132fb-6a4a-436e-adf5-759de63fed4a"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Temporal alignment: Synchronize events with IMU measurements\n",
    "# ============================================================================\n",
    "# Event cameras and IMU may not start/stop at exactly the same time.\n",
    "# We find the overlapping time range to ensure valid event-label pairs.\n",
    "\n",
    "# Determine the common time window\n",
    "start_time = max(timestamps[0], events['t'][0])\n",
    "end_time   = min(timestamps[-1],  events['t'][-1])\n",
    "\n",
    "# Filter IMU data to the valid time range\n",
    "mask_IMU = (timestamps >= start_time) & (timestamps <= end_time)\n",
    "timestamps = timestamps[mask_IMU]\n",
    "roll = roll[mask_IMU]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aef18e2",
   "metadata": {
    "id": "6aef18e2"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Time-based slicing: Convert continuous event stream into discrete frames\n",
    "# ============================================================================\n",
    "# Event cameras produce asynchronous events. We group them into fixed time windows\n",
    "# to create a sequence of \"frames\" for the SNN.\n",
    "\n",
    "time_window = 10000  # 10,000 μs = 10 ms\n",
    "\n",
    "# Slice events into time windows\n",
    "events_per_frame = tonic.slicers.slice_events_by_time(\n",
    "    events, \n",
    "    time_window=time_window, \n",
    "    start_time=start_time, \n",
    "    end_time=end_time\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225330fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "225330fd",
    "outputId": "e0cb04f4-5b39-48a7-ca8a-0643f0e931b8"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Label interpolation and assignment\n",
    "# ============================================================================\n",
    "# IMU-derived roll estimates are discrete in time; we need one label per event frame\n",
    "# so we interpolate to the end timestamp of each window.\n",
    "\n",
    "# Create interpolation function for roll angle\n",
    "interp_roll  = interp1d(timestamps, roll, fill_value=\"extrapolate\")\n",
    "\n",
    "# Compute the end timestamp for each window\n",
    "# Window i ends at: start_time + (i+1) * time_window\n",
    "# Use dtype=int64 to prevent overflow when multiplying large numbers\n",
    "ev_timestamps = start_time + np.arange(1, len(events_per_frame) + 1, dtype=np.int64) * time_window\n",
    "\n",
    "# Interpolate angles at these timestamps\n",
    "roll_vals = interp_roll(ev_timestamps)\n",
    "\n",
    "print(f\"Labels assigned successfully!\")\n",
    "print(f\"Total grouped events: {len(events_per_frame)}\")\n",
    "print(f\"Total labels assigned: {len(roll_vals)}\")\n",
    "print(f\"Frames read: {len(events_per_frame)}\")\n",
    "print(f\"Events read: {len(events)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d6a0d3",
   "metadata": {
    "id": "02d6a0d3"
   },
   "outputs": [],
   "source": [
    "START_FRAME = 0  \n",
    "END_FRAME = -2500\n",
    "\n",
    "events_per_frame = events_per_frame[START_FRAME:END_FRAME]\n",
    "roll_vals = roll_vals[START_FRAME:END_FRAME]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3189ced6",
   "metadata": {
    "id": "3189ced6"
   },
   "source": [
    "## Dataset Classes and Train/Val/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3718dcc",
   "metadata": {
    "id": "d3718dcc"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Base dataset for individual frames\n",
    "# ============================================================================\n",
    "class RotatingBarDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Basic dataset that wraps sliced events and their corresponding labels.\n",
    "    Each item returns a single time window of events and its target angle.\n",
    "    \"\"\"\n",
    "    def __init__(self, sliced_events, labels, transform=None):\n",
    "        self.sliced_events = sliced_events\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sliced_events)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        events = self.sliced_events[idx]\n",
    "        target = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            events = self.transform(events)\n",
    "\n",
    "        return events, target\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Fixed-length sequences for training/validation\n",
    "# ============================================================================\n",
    "class SequenceDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Splits a long temporal sequence into multiple fixed-length subsequences.\n",
    "\n",
    "    Note:\n",
    "        Any remaining frames that don't fit into a complete sequence are discarded.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_dataset, seq_length=5000, expected_shape=(2, 346, 260)):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.seq_length = seq_length\n",
    "        self.expected_shape = expected_shape\n",
    "        self.total_length = len(base_dataset)\n",
    "\n",
    "        # Compute number of complete sequences (discard remainder)\n",
    "        self.num_sequences = self.total_length // seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_sequences\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Compute start and end indices for this sequence\n",
    "        start_idx = idx * self.seq_length\n",
    "        end_idx = start_idx + self.seq_length\n",
    "\n",
    "        frames = []\n",
    "        labels = []\n",
    "\n",
    "        # Collect all frames and labels in this sequence\n",
    "        for i in range(start_idx, end_idx):\n",
    "            frame, label = self.base_dataset[i]\n",
    "\n",
    "            # Convert to tensor if needed\n",
    "            if isinstance(frame, np.ndarray):\n",
    "                frame = torch.from_numpy(frame)\n",
    "            \n",
    "            frame = frame.squeeze(0)  # Remove n_event_bins dimension [1, C, H, W] -> [C, H, W]\n",
    "\n",
    "            # Handle potential transpose issues (ensure [C, H, W] format)\n",
    "            if frame.shape != self.expected_shape:\n",
    "                frame = frame.permute(0, 2, 1)  # [C, W, H] -> [C, H, W]\n",
    "\n",
    "            frames.append(frame)\n",
    "            labels.append(label)\n",
    "\n",
    "        # Stack into temporal sequences\n",
    "        frames = torch.stack(frames, dim=0).float()  # [T, C, H, W]\n",
    "        labels = torch.tensor(labels, dtype=torch.float32)  # [T]\n",
    "\n",
    "        return frames, labels\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Continuous sequence for testing\n",
    "# ============================================================================\n",
    "class ContinuousDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Loads the entire sequence without splitting, used for testing.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_dataset, expected_shape=(2, 346, 260)):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.expected_shape = expected_shape\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1  # Single item: the entire sequence\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the entire sequence\n",
    "        frames = []\n",
    "        labels = []\n",
    "\n",
    "        for i in range(len(self.base_dataset)):\n",
    "            frame, label = self.base_dataset[i]\n",
    "\n",
    "            if isinstance(frame, np.ndarray):\n",
    "                frame = torch.from_numpy(frame)\n",
    "            \n",
    "            frame = frame.squeeze(0)  # Remove n_event_bins dimension\n",
    "\n",
    "            # Handle potential transpose issues\n",
    "            if frame.shape != self.expected_shape:\n",
    "                frame = frame.permute(0, 2, 1)  # [C, W, H] -> [C, H, W]\n",
    "\n",
    "            frames.append(frame)\n",
    "            labels.append(label)\n",
    "\n",
    "        # Stack: [T, C, H, W] and [T]\n",
    "        frames = torch.stack(frames, dim=0).float()\n",
    "        labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "        return frames, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9c807b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff9c807b",
    "outputId": "4198af28-bf74-45a0-dcca-d63ff33630a6"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Train/Validation/Test Split\n",
    "# ============================================================================\n",
    "\n",
    "input_data = events_per_frame\n",
    "labels = roll_vals\n",
    "total_samples = len(input_data)\n",
    "\n",
    "print(f\"Total samples in dataset: {total_samples}\")\n",
    "\n",
    "# Define split ratios\n",
    "test_split = 0.05   # for final testing\n",
    "val_split  = 0.07   # for validation during training\n",
    "train_split = 1.0 - test_split - val_split  # for training\n",
    "\n",
    "# Calculate split indices (temporal order maintained)\n",
    "train_end = int(train_split * total_samples)\n",
    "val_end   = int((train_split + val_split) * total_samples)\n",
    "\n",
    "# Perform temporal split (NO SHUFFLE!)\n",
    "train_events = input_data[:train_end]\n",
    "train_labels = labels[:train_end]\n",
    "\n",
    "val_events = input_data[train_end:val_end]\n",
    "val_labels = labels[train_end:val_end]\n",
    "\n",
    "test_events = input_data[val_end:]\n",
    "test_labels = labels[val_end:]\n",
    "\n",
    "# ============================================================================\n",
    "# Create datasets with event-to-frame transformation\n",
    "# ============================================================================\n",
    "H, W = 260, 346  # DAVIS346 resolution (height, width)\n",
    "\n",
    "# Transform events to frames with ON/OFF channels\n",
    "frame_transform = transforms.ToFrame(\n",
    "    sensor_size=(W, H, 2),  # (width, height, polarities)\n",
    "    n_event_bins=1  # Single bin per time window\n",
    ")\n",
    "\n",
    "# Create base datasets\n",
    "train_dataset = RotatingBarDataset(train_events, train_labels, transform=frame_transform)\n",
    "val_dataset   = RotatingBarDataset(val_events, val_labels, transform=frame_transform)\n",
    "test_dataset  = RotatingBarDataset(test_events, test_labels, transform=frame_transform)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)} samples ({train_split*100:.1f}%)\")\n",
    "print(f\"Val dataset size:   {len(val_dataset)} samples ({val_split*100:.1f}%)\")\n",
    "print(f\"Test dataset size:  {len(test_dataset)} samples ({test_split*100:.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# Cache training data in memory for faster access\n",
    "# ============================================================================\n",
    "cached_trainset = MemoryCachedDataset(\n",
    "    train_dataset,\n",
    "    transform=lambda x: torch.from_numpy(x).float(),\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# Create sequence datasets\n",
    "# ============================================================================\n",
    "SEQ_LENGTH = 2000  # Timesteps per sequence (for TBPTT)\n",
    "BATCH_SIZE = 4     # Number of sequences processed in parallel\n",
    "\n",
    "# Training and validation use fixed-length sequences\n",
    "trainset = SequenceDataset(cached_trainset, seq_length=SEQ_LENGTH, expected_shape=(2, H, W))\n",
    "valset = SequenceDataset(val_dataset, seq_length=SEQ_LENGTH, expected_shape=(2, H, W))\n",
    "\n",
    "# Test uses continuous sequence\n",
    "testset = ContinuousDataset(test_dataset, expected_shape=(2, H, W))\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Custom collate function for time-first batching\n",
    "# ============================================================================\n",
    "def collate_time_first(batch):\n",
    "    \"\"\"\n",
    "    Collate function that arranges data as [T, B, ...] instead of [B, T, ...].\n",
    "    This is more natural for processing temporal sequences with SNNs.\n",
    "    \"\"\"\n",
    "    frames, labels = zip(*batch)\n",
    "    frames = torch.stack(frames, dim=1)   # [T, B, C, H, W]\n",
    "    labels = torch.stack(labels, dim=1)   # [T, B]\n",
    "    return frames, labels\n",
    "\n",
    "# ============================================================================\n",
    "# Create DataLoaders\n",
    "# ============================================================================\n",
    "trainloader = DataLoader(\n",
    "    trainset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=collate_time_first,\n",
    "    shuffle=True  # Shuffle sequences\n",
    ")\n",
    "\n",
    "valloader = DataLoader(\n",
    "    valset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=collate_time_first,\n",
    "    shuffle=False  # No shuffling for validation\n",
    ")\n",
    "\n",
    "testloader = DataLoader(\n",
    "    testset,\n",
    "    batch_size=1,\n",
    "    collate_fn=collate_time_first,\n",
    "    shuffle=False  # No shuffling for testing\n",
    ")\n",
    "\n",
    "print(f\"\\nDataLoaders created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db0f81c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0db0f81c",
    "outputId": "0c472490-7b2d-41e4-bc9c-44a5af35eed3"
   },
   "outputs": [],
   "source": [
    "# Verify train/val/test split distribution\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=False)\n",
    "\n",
    "# ------------------------\n",
    "# Train\n",
    "# ------------------------\n",
    "axes[0].plot(train_labels * 180 / np.pi, linewidth=0.8, alpha=0.7)\n",
    "axes[0].set_title(f'Train Data Distribution ({len(train_labels)} samples)')\n",
    "axes[0].set_xlabel('Sample Index')\n",
    "axes[0].set_ylabel('Angle (degrees)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# ------------------------\n",
    "# Validation\n",
    "# ------------------------\n",
    "axes[1].plot(val_labels * 180 / np.pi, linewidth=0.8, alpha=0.7)\n",
    "axes[1].set_title(f'Validation Data Distribution ({len(val_labels)} samples)')\n",
    "axes[1].set_xlabel('Sample Index')\n",
    "axes[1].set_ylabel('Angle (degrees)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# ------------------------\n",
    "# Test\n",
    "# ------------------------\n",
    "axes[2].plot(test_labels * 180 / np.pi, linewidth=0.8, alpha=0.7)\n",
    "axes[2].set_title(f'Test Data Distribution ({len(test_labels)} samples)')\n",
    "axes[2].set_xlabel('Sample Index')\n",
    "axes[2].set_ylabel('Angle (degrees)')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ------------------------\n",
    "# Ranges\n",
    "# ------------------------\n",
    "print(f\"\\nTrain data range: [{train_labels.min()*180/np.pi:.2f}°, {train_labels.max()*180/np.pi:.2f}°]\")\n",
    "print(f\"Val data range:   [{val_labels.min()*180/np.pi:.2f}°, {val_labels.max()*180/np.pi:.2f}°]\")\n",
    "print(f\"Test data range:  [{test_labels.min()*180/np.pi:.2f}°, {test_labels.max()*180/np.pi:.2f}°]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb4faac",
   "metadata": {
    "id": "6eb4faac"
   },
   "outputs": [],
   "source": [
    "# Visualize 5 sequences from trainloader, playing at 10 fps\n",
    "#visualize_sequence_from_trainloader(trainloader, n_sequences=5, playback_fps=10, scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03ca961",
   "metadata": {
    "id": "f03ca961"
   },
   "source": [
    "## Defining Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1752c885",
   "metadata": {
    "id": "1752c885"
   },
   "source": [
    "### Normalization Layers\n",
    "\n",
    "This section implements three normalization strategies for SNNs:\n",
    "\n",
    "1. **Batch Normalization (BN)**: Standard BatchNorm2d\n",
    "2. **RMS Normalization (RMS)**: Root Mean Square normalization\n",
    "3. **Multiply (MUL)**: Simple learnable scaling\n",
    "\n",
    "These are crucial for SNNs because:\n",
    "- Neurons only spike when input exceeds threshold\n",
    "- Without normalization, activations may be too small → no spikes → vanishing gradient\n",
    "- Proper scaling enables spike propagation through deep networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b40bc3b",
   "metadata": {
    "id": "4b40bc3b"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# RMS Normalization\n",
    "# ============================================================================\n",
    "class RMSNorm2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Root Mean Square Normalization for 2D feature maps.\n",
    "    \n",
    "    Unlike BatchNorm, RMSNorm:\n",
    "    - Does not center the data (no mean subtraction)\n",
    "    - Only normalizes by the RMS (scale only)\n",
    "    \n",
    "    Formula: x_norm = x / sqrt(mean(x^2) + eps)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_features, eps=1e-5, affine=True):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.affine = affine\n",
    "\n",
    "        if self.affine:\n",
    "            # Learnable per-channel scaling parameter\n",
    "            self.weight = nn.Parameter(torch.ones(1, num_features, 1, 1))\n",
    "        else:\n",
    "            self.register_parameter('weight', None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, C, H, W]\n",
    "        # Compute mean squared value over spatial dimensions (H, W)\n",
    "        ms = x.pow(2).mean(dim=(2, 3), keepdim=True)  # [B, C, 1, 1]\n",
    "        \n",
    "        # Compute RMS\n",
    "        rms = torch.sqrt(ms + self.eps)\n",
    "\n",
    "        # Normalize\n",
    "        x_norm = x / rms\n",
    "\n",
    "        # Apply learnable scaling if enabled\n",
    "        if self.weight is not None:\n",
    "            return x_norm * self.weight\n",
    "        return x_norm\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Simple Scaling (Multiply)\n",
    "# ============================================================================\n",
    "class MultiplyBy(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple multiplication by a learnable or fixed scalar.\n",
    "    \n",
    "    From: https://github.com/urancon/StereoSpike/blob/main/network/blocks.py\n",
    "    \"\"\"\n",
    "    def __init__(self, weight: float = 5., learnable: bool = True) -> None:\n",
    "        super(MultiplyBy, self).__init__()\n",
    "\n",
    "        if learnable:\n",
    "            # Learnable parameter\n",
    "            self.weight = Parameter(Tensor([weight]))\n",
    "        else:\n",
    "            # Fixed value\n",
    "            self.weight = weight\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        return torch.mul(input, self.weight)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Normalization Factory Function\n",
    "# ============================================================================\n",
    "def get_norm_layer(norm_type: str, num_features: int, learnable: bool = True, eps: float = 1e-5, init_scale: float = 5.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Factory function to create normalization layers.\n",
    "    \"\"\"\n",
    "    if norm_type == \"BN\":\n",
    "        # Standard BatchNorm2d\n",
    "        return nn.BatchNorm2d(num_features, affine=learnable, eps=eps)\n",
    "\n",
    "    elif norm_type == \"RMS\":\n",
    "        # RMS Normalization\n",
    "        return RMSNorm2d(num_features, eps=eps, affine=learnable)\n",
    "\n",
    "    elif norm_type == \"MUL\":\n",
    "        # Simple scaling\n",
    "        return MultiplyBy(init_scale, learnable=learnable)\n",
    "\n",
    "    elif norm_type is None:\n",
    "        # No normalization\n",
    "        return nn.Identity()\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown normalization type: {norm_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9794bec2",
   "metadata": {
    "id": "9794bec2"
   },
   "source": [
    "### Building Blocks\n",
    "\n",
    "This section defines the fundamental building blocks for the SNN:\n",
    "\n",
    "1. **PlainBlock**: Sequential conv-LIF layers without residual connections\n",
    "2. **SpikingBlock**: Spiking ResNet block with residual connections  \n",
    "3. **SEWBlock**: Spiking Element-Wise block with flexible connection functions\n",
    "\n",
    "Adapted from: https://github.com/fangwei123456/Spike-Element-Wise-ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7be4b1",
   "metadata": {
    "id": "7e7be4b1"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Convolution Helpers\n",
    "# ============================================================================\n",
    "def conv3x3(in_ch, out_ch, stride=1, norm_type=\"BN\", learnable=True, init_scale=5.0):\n",
    "    \"\"\"\n",
    "    3x3 convolution with normalization.\n",
    "    \"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "        get_norm_layer(norm_type, out_ch, learnable=learnable, init_scale=init_scale)\n",
    "    )\n",
    "\n",
    "\n",
    "def conv1x1(in_ch, out_ch, stride=1, norm_type=\"BN\", learnable=True, init_scale=5.0):\n",
    "    \"\"\"\n",
    "    1x1 convolution with normalization.\n",
    "    \"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=stride, bias=False),\n",
    "        get_norm_layer(norm_type, out_ch, learnable=learnable, init_scale=init_scale)\n",
    "    )\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Plain Block (No Residual Connection)\n",
    "# ============================================================================\n",
    "class PlainBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Plain convolutional block without residual connections.\n",
    "    \n",
    "    Architecture:\n",
    "        Conv3x3 → Norm → LIF → Conv3x3 → Norm → LIF\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, mid_channels, tau=2.0, Plif=False, v_reset=0.0,\n",
    "                 surrogate_function=surrogate.ATan(), stride1=1, stride2=1,\n",
    "                 norm_type=\"BN\", learnable_norm=True, init_scale=5.0):\n",
    "        super(PlainBlock, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            # First conv-norm-LIF\n",
    "            conv3x3(in_channels, mid_channels, stride=stride1, norm_type=norm_type, learnable=learnable_norm, init_scale=init_scale),\n",
    "            neuron.ParametricLIFNode(init_tau=tau, v_reset=v_reset, surrogate_function=surrogate_function, detach_reset=True)\n",
    "            if Plif else neuron.LIFNode(tau=tau, v_reset=v_reset, surrogate_function=surrogate_function, detach_reset=True),\n",
    "\n",
    "            # Second conv-norm-LIF\n",
    "            conv3x3(mid_channels, in_channels, stride=stride2, norm_type=norm_type, learnable=learnable_norm, init_scale=init_scale),\n",
    "            neuron.ParametricLIFNode(init_tau=tau, v_reset=v_reset, surrogate_function=surrogate_function, detach_reset=True)\n",
    "            if Plif else neuron.LIFNode(tau=tau, v_reset=v_reset, surrogate_function=surrogate_function, detach_reset=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Spiking ResNet Block\n",
    "# ============================================================================\n",
    "class SpikingBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Spiking ResNet block with residual connection.\n",
    "    \n",
    "    Architecture:\n",
    "        x → Conv3x3 → Norm → LIF → Conv3x3 → Norm → (+) → LIF → out\n",
    "        └──────────────── downsample ────────────────┘\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, mid_channels, tau=2.0, Plif=False, v_reset=0.0,\n",
    "                 surrogate_function=surrogate.ATan(), stride1=1, stride2=1,\n",
    "                 norm_type=\"BN\", learnable_norm=True, init_scale=5.0):\n",
    "        super(SpikingBlock, self).__init__()\n",
    "\n",
    "        # Main path\n",
    "        self.conv = nn.Sequential(\n",
    "            conv3x3(in_channels, mid_channels, stride=stride1, norm_type=norm_type, learnable=learnable_norm, init_scale=init_scale),\n",
    "            neuron.ParametricLIFNode(init_tau=tau, v_reset=v_reset, surrogate_function=surrogate_function, detach_reset=True)\n",
    "            if Plif else neuron.LIFNode(tau=tau, v_reset=v_reset, surrogate_function=surrogate_function, detach_reset=True),\n",
    "\n",
    "            nn.Conv2d(mid_channels, in_channels, kernel_size=3, padding=1, stride=stride2, bias=False),\n",
    "            get_norm_layer(norm_type=norm_type, num_features=in_channels, learnable=learnable_norm, init_scale=init_scale)\n",
    "        )\n",
    "\n",
    "        # Output LIF (after addition)\n",
    "        self.sn = neuron.ParametricLIFNode(init_tau=tau, v_reset=v_reset, surrogate_function=surrogate_function, detach_reset=True) \\\n",
    "                  if Plif else neuron.LIFNode(tau=tau, v_reset=v_reset, surrogate_function=surrogate_function, detach_reset=True)\n",
    "\n",
    "        # Shortcut connection (downsample if needed)\n",
    "        if stride1 == 2:\n",
    "            self.downsample = conv1x1(in_channels, in_channels, stride=2, norm_type=norm_type, learnable=learnable_norm, init_scale=init_scale)\n",
    "        else:\n",
    "            self.downsample = nn.Identity()\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # Residual connection: x + conv(x)\n",
    "        return self.sn(self.downsample(x) + self.conv(x))\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# SEW (Spiking Element-Wise) Block\n",
    "# ============================================================================\n",
    "class SEWBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Spiking Element-Wise residual block with flexible connection functions.\n",
    "    \n",
    "    Architecture:\n",
    "        x → Conv3x3 → Norm → LIF → Conv3x3 → Norm → LIF → (+) → out\n",
    "        └──────────────── downsample → LIF ────────────────┘\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, mid_channels, tau=2.0, Plif=False, v_reset=0.0,\n",
    "                 surrogate_function=surrogate.ATan(), stride1=1, stride2=1,\n",
    "                 connect_f=\"ADD\", norm_type=\"BN\", learnable_norm=True, init_scale=5.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.connect_f = connect_f\n",
    "\n",
    "        # First conv-norm-LIF\n",
    "        self.conv1 = conv3x3(in_channels, mid_channels, stride=stride1, norm_type=norm_type, learnable=learnable_norm, init_scale=init_scale)\n",
    "        self.lif1 = neuron.ParametricLIFNode(init_tau=tau, v_reset=v_reset, surrogate_function=surrogate_function, detach_reset=True) \\\n",
    "                    if Plif else neuron.LIFNode(tau=tau, v_reset=v_reset, surrogate_function=surrogate_function, detach_reset=True)\n",
    "\n",
    "        # Second conv-norm-LIF\n",
    "        self.conv2 = conv3x3(mid_channels, in_channels, stride=stride2, norm_type=norm_type, learnable=learnable_norm, init_scale=init_scale)\n",
    "        self.lif2 = neuron.ParametricLIFNode(init_tau=tau, v_reset=v_reset, surrogate_function=surrogate_function, detach_reset=True) \\\n",
    "                    if Plif else neuron.LIFNode(tau=tau, v_reset=v_reset, surrogate_function=surrogate_function, detach_reset=True)\n",
    "\n",
    "        # Shortcut (with LIF)\n",
    "        if stride1 == 2:\n",
    "            self.downsample = nn.Sequential(\n",
    "                conv1x1(in_channels, in_channels, stride=2, norm_type=norm_type, learnable=learnable_norm, init_scale=init_scale),\n",
    "                neuron.ParametricLIFNode(init_tau=tau, v_reset=v_reset, surrogate_function=surrogate_function, detach_reset=True)\n",
    "                if Plif else neuron.LIFNode(tau=tau, v_reset=v_reset, surrogate_function=surrogate_function, detach_reset=True)\n",
    "            )\n",
    "        else:\n",
    "            self.downsample = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut path (produces spikes)\n",
    "        identity = self.downsample(x)\n",
    "\n",
    "        # Main path\n",
    "        spk1 = self.lif1(self.conv1(x))\n",
    "        spk2 = self.lif2(self.conv2(spk1))\n",
    "\n",
    "        # Apply connection function\n",
    "        if self.connect_f == \"ADD\":\n",
    "            return spk2 + identity\n",
    "        elif self.connect_f == \"AND\":\n",
    "            return spk2 * identity \n",
    "        elif self.connect_f == \"IAND\":\n",
    "            return identity * (1 - spk2) \n",
    "        else:\n",
    "            raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087869d1",
   "metadata": {
    "id": "087869d1"
   },
   "source": [
    "### Main SNN Architecture\n",
    "\n",
    "The `SNN_Net` class defines the complete network architecture:\n",
    "\n",
    "**Architecture Overview:**\n",
    "1. **Convolutional blocks**: Multiple blocks (Plain/Spiking/SEW) with progressive downsampling\n",
    "2. **Adaptive pooling**: MaxPool layers reduce spatial dimensions\n",
    "3. **Fully connected layers**: Maps features to regression output\n",
    "4. **Output LIF**: Special LIF with infinite threshold for regression (accumulates membrane potential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5c8cc7",
   "metadata": {
    "id": "2a5c8cc7"
   },
   "outputs": [],
   "source": [
    "class SNN_Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Complete Spiking Neural Network for event-based regression.\n",
    "    \n",
    "    This network processes event camera frames through a series of convolutional\n",
    "    blocks followed by fully connected layers to predict a continuous angle value.\n",
    "    \n",
    "    Architecture:\n",
    "        Input [B, 2, 346, 260] (ON/OFF event frames)\n",
    "          ↓\n",
    "        Convolutional Blocks (with normalization + LIF neurons)\n",
    "          ↓\n",
    "        Adaptive Pooling (progressive downsampling)\n",
    "          ↓\n",
    "        Flatten\n",
    "          ↓\n",
    "        FC Layer + LIF\n",
    "          ↓\n",
    "        Output FC + LIF (infinite threshold for regression)\n",
    "          ↓\n",
    "        Output: Membrane potential (continuous value)\n",
    "    \n",
    "    Note:\n",
    "        For temporal sequences, call forward() for each timestep T.\n",
    "        Remember to reset neuron states between sequences with functional.reset_net(model).\n",
    "    \"\"\"\n",
    "    def __init__(self, tau=2.0, final_tau=20.0, layer_list=None, hidden=256, v_reset=0.0,\n",
    "                 surrogate_function=surrogate.ATan(), connect_f=\"ADD\", Plif=False, \n",
    "                 norm_type=\"BN\", learnable_norm=True, init_scale=5.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.norm_type = norm_type\n",
    "        \n",
    "        # ====================================================================\n",
    "        # Build sequential convolution pipeline\n",
    "        # ====================================================================\n",
    "        conv_blocks = []\n",
    "        in_channels = 2  # Start with 2 channels (ON/OFF events)\n",
    "\n",
    "        for cfg in layer_list:\n",
    "            channels = cfg[\"channels\"]\n",
    "            mid_channels = cfg[\"mid_channels\"]\n",
    "\n",
    "            # Channel adjustment layer (if needed)\n",
    "            if in_channels != channels:\n",
    "                if cfg[\"up_kernel_size\"] == 3:\n",
    "                    conv_blocks.append(conv3x3(in_channels, channels, norm_type=norm_type, learnable=learnable_norm, init_scale=init_scale))\n",
    "                elif cfg[\"up_kernel_size\"] == 1:\n",
    "                    conv_blocks.append(conv1x1(in_channels, channels, norm_type=norm_type, learnable=learnable_norm, init_scale=init_scale))\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "\n",
    "                # Add LIF after channel adjustment\n",
    "                conv_blocks.append(\n",
    "                    neuron.ParametricLIFNode(init_tau=tau, v_reset=v_reset, surrogate_function=surrogate_function, detach_reset=True)\n",
    "                    if Plif else neuron.LIFNode(tau=tau, v_reset=v_reset, surrogate_function=surrogate_function, detach_reset=True)\n",
    "                )\n",
    "                in_channels = channels\n",
    "\n",
    "            # Add building blocks\n",
    "            for _ in range(cfg[\"num_blocks\"]):\n",
    "                if cfg[\"block_type\"] == \"sew\":\n",
    "                    conv_blocks.append(\n",
    "                        SEWBlock(in_channels, mid_channels, tau=tau, Plif=Plif, v_reset=v_reset,\n",
    "                                stride1=cfg[\"stride_1\"], stride2=cfg[\"stride_2\"], connect_f=connect_f,  \n",
    "                                norm_type=norm_type, learnable_norm=learnable_norm, init_scale=init_scale)\n",
    "                    )\n",
    "                elif cfg[\"block_type\"] == \"plain\":\n",
    "                    conv_blocks.append(\n",
    "                        PlainBlock(in_channels, mid_channels, tau=tau, Plif=Plif, v_reset=v_reset,\n",
    "                                  stride1=cfg[\"stride_1\"], stride2=cfg[\"stride_2\"],\n",
    "                                  norm_type=norm_type, learnable_norm=learnable_norm, init_scale=init_scale)\n",
    "                    )\n",
    "                elif cfg[\"block_type\"] == \"spiking\":\n",
    "                    conv_blocks.append(\n",
    "                        SpikingBlock(in_channels, mid_channels, tau=tau, Plif=Plif, v_reset=v_reset,\n",
    "                                    stride1=cfg[\"stride_1\"], stride2=cfg[\"stride_2\"],\n",
    "                                    norm_type=norm_type, learnable_norm=learnable_norm, init_scale=init_scale)\n",
    "                    )\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "\n",
    "            # Add MaxPool (if specified)\n",
    "            #if \"k_pool\" in cfg and cfg[\"k_pool\"] > 1:\n",
    "            if \"k_pool\" in cfg:\n",
    "                conv_blocks.append(nn.MaxPool2d(kernel_size=cfg[\"k_pool\"]))\n",
    "\n",
    "        self.conv = nn.ModuleList(conv_blocks)\n",
    "\n",
    "        # ====================================================================\n",
    "        # Automatic computation of flattened feature dimension\n",
    "        # ====================================================================\n",
    "        # Run a dummy forward pass to determine the output size\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, 2, 346, 260)  # DAVIS346 input size\n",
    "            for m in self.conv:\n",
    "                dummy = m(dummy)\n",
    "            flat_dim = dummy.numel()\n",
    "\n",
    "        # ====================================================================\n",
    "        # Fully Connected Layers\n",
    "        # ====================================================================\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(flat_dim, hidden, bias=False)\n",
    "        \n",
    "        # Hidden LIF neurons\n",
    "        self.lif_hidden = (neuron.ParametricLIFNode(init_tau=tau, v_reset=v_reset, surrogate_function=surrogate_function, detach_reset=True) \n",
    "                          if Plif else neuron.LIFNode(tau=tau, v_reset=v_reset, surrogate_function=surrogate_function, detach_reset=True))\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc_out = nn.Linear(hidden, 1, bias=False)\n",
    "        \n",
    "        # Output LIF with INFINITE threshold (for regression)\n",
    "        # This neuron never spikes - we read its membrane potential as the prediction\n",
    "        self.lif_out = neuron.LIFNode(tau=final_tau, v_threshold=float('inf'), \n",
    "                                      surrogate_function=surrogate_function, detach_reset=True)\n",
    "\n",
    "    def detach(self):\n",
    "        \"\"\"\n",
    "        Detach membrane potentials of all LIF neurons.\n",
    "\n",
    "        Used in TBPTT (Truncated Backpropagation Through Time) to truncate\n",
    "        gradients and prevent backpropagation through the entire sequence.\n",
    "        \"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, neuron.BaseNode):\n",
    "                m.v.detach_()\n",
    "\n",
    "    # ========================================================================\n",
    "    # SPIKE ACTIVITY MONITORING\n",
    "    # ========================================================================\n",
    "    def _register_spike_hooks(self):\n",
    "        \"\"\"Register forward hooks on all LIF layers to record spike activity.\"\"\"\n",
    "        self.spike_record = {}\n",
    "        self.hooks = []\n",
    "\n",
    "        for name, module in self.named_modules():\n",
    "            if isinstance(module, neuron.BaseNode):   # LIF or PLIF neurons\n",
    "                hook = module.register_forward_hook(self._make_spike_hook(name))\n",
    "                self.hooks.append(hook)\n",
    "\n",
    "    def _make_spike_hook(self, name):\n",
    "        \"\"\"Create a hook function that captures spike output.\"\"\"\n",
    "        def hook(module, inp, out):\n",
    "            # Store spikes for this layer \n",
    "            self.spike_record[name] = out.detach().clone()\n",
    "        return hook\n",
    "\n",
    "    def enable_spike_recording(self):\n",
    "        \"\"\"Enable spike activity recording for all LIF neurons.\"\"\"\n",
    "        self._register_spike_hooks()\n",
    "\n",
    "    def disable_spike_recording(self):\n",
    "        \"\"\"Disable spike recording and clean up hooks.\"\"\"\n",
    "        for h in self.hooks:\n",
    "            h.remove()\n",
    "        self.hooks = []\n",
    "        self.spike_record = {}\n",
    "\n",
    "    # ========================================================================\n",
    "    # NORMALIZATION STATISTICS MONITORING\n",
    "    # ========================================================================\n",
    "    def _register_norm_hooks(self):\n",
    "        \"\"\"Register hooks on all normalization layers to capture statistics.\"\"\"\n",
    "        self.norm_stats = {}\n",
    "        self.norm_hooks = []\n",
    "\n",
    "        # Determine which normalization type to monitor\n",
    "        if self.norm_type == \"BN\":\n",
    "            module_type = nn.BatchNorm2d\n",
    "        elif self.norm_type == \"RMS\":\n",
    "            module_type = RMSNorm2d\n",
    "        else:\n",
    "            print(f\"No normalization monitoring available for norm_type={self.norm_type}\")\n",
    "            return\n",
    "\n",
    "        norm_counter = 0\n",
    "        for name, module in self.named_modules():\n",
    "            if isinstance(module, module_type):\n",
    "                hook = module.register_forward_hook(\n",
    "                    self._make_norm_hook(f\"{self.norm_type}_{norm_counter}_{name}\")\n",
    "                )\n",
    "                self.norm_hooks.append(hook)\n",
    "                norm_counter += 1\n",
    "\n",
    "    def _make_norm_hook(self, layer_name):\n",
    "        \"\"\"Create a hook that captures normalization input/output statistics.\"\"\"\n",
    "        def hook(module, inp, out):\n",
    "            input_tensor = inp[0].detach()\n",
    "            output_tensor = out.detach()\n",
    "\n",
    "            # Compute per-channel statistics\n",
    "            # Input/output shape: [B, C, H, W]\n",
    "            B, C, H, W = input_tensor.shape\n",
    "\n",
    "            # Flatten spatial dimensions: [B, C, H*W]\n",
    "            input_flat = input_tensor.view(B, C, -1)\n",
    "            output_flat = output_tensor.view(B, C, -1)\n",
    "\n",
    "            # Store comprehensive statistics\n",
    "            self.norm_stats[layer_name] = {\n",
    "                # INPUT statistics (before normalization)\n",
    "                'input_mean_per_channel': input_flat.mean(dim=(0, 2)).cpu().numpy(),  # [C]\n",
    "                'input_std_per_channel': input_flat.std(dim=(0, 2)).cpu().numpy(),\n",
    "                'input_min_per_channel': input_flat.min(dim=2)[0].mean(dim=0).cpu().numpy(),\n",
    "                'input_max_per_channel': input_flat.max(dim=2)[0].mean(dim=0).cpu().numpy(),\n",
    "\n",
    "                # OUTPUT statistics (after normalization)\n",
    "                'output_mean_per_channel': output_flat.mean(dim=(0, 2)).cpu().numpy(),\n",
    "                'output_std_per_channel': output_flat.std(dim=(0, 2)).cpu().numpy(),\n",
    "                'output_min_per_channel': output_flat.min(dim=2)[0].mean(dim=0).cpu().numpy(),\n",
    "                'output_max_per_channel': output_flat.max(dim=2)[0].mean(dim=0).cpu().numpy(),\n",
    "            }\n",
    "        return hook\n",
    "\n",
    "    def enable_norm_monitoring(self):\n",
    "        \"\"\"Enable normalization statistics monitoring.\"\"\"\n",
    "        self._register_norm_hooks()\n",
    "\n",
    "    def disable_norm_monitoring(self):\n",
    "        \"\"\"Disable normalization monitoring and clean up hooks.\"\"\"\n",
    "        for hook in self.norm_hooks:\n",
    "            hook.remove()\n",
    "        self.norm_hooks = []\n",
    "        self.norm_stats = {}\n",
    "\n",
    "    def get_norm_stats(self):\n",
    "        \"\"\"Return captured normalization statistics.\"\"\"\n",
    "        return self.norm_stats\n",
    "\n",
    "    # ========================================================================\n",
    "    # FORWARD PASS\n",
    "    # ========================================================================\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for a single timestep.\n",
    "        Note:\n",
    "            This processes ONE timestep. For temporal sequences, call this\n",
    "            method T times (once per frame) without resetting neuron states.\n",
    "        \"\"\"\n",
    "        out = x\n",
    "\n",
    "        # Pass through convolutional blocks\n",
    "        for m in self.conv:\n",
    "            out = m(out)\n",
    "\n",
    "        # Fully connected layers\n",
    "        out = self.flatten(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.lif_hidden(out)\n",
    "\n",
    "        # Output layer (LIF with infinite threshold)\n",
    "        out = self.fc_out(out)\n",
    "        _ = self.lif_out(out)\n",
    "\n",
    "        # Return membrane potential (continuous value for regression)\n",
    "        return self.lif_out.v "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92947e91",
   "metadata": {
    "id": "92947e91"
   },
   "source": [
    "### Layer Configurations\n",
    "\n",
    "This section defines three different layer configurations for experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae97c95",
   "metadata": {
    "id": "9ae97c95"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SEW (Spiking Element-Wise) Architecture\n",
    "# ============================================================================\n",
    "layer_list_sew = [\n",
    "    # STEM: Early aggressive downsampling to reduce computational cost\n",
    "    {\n",
    "        'channels': 16,          # Output channels\n",
    "        'up_kernel_size': 3,     # 3x3 conv for initial feature extraction\n",
    "        'mid_channels': 16,      # Intermediate channels in block\n",
    "        'num_blocks': 1,         # Single block\n",
    "        'block_type': 'sew',     # SEW block type\n",
    "        'k_pool': 2,             # 2x2 MaxPool → /2 spatial reduction\n",
    "        'stride_1': 2,           # First conv: stride 2 → /2 reduction\n",
    "        'stride_2': 1            # Second conv: stride 1 → preserve size\n",
    "    },\n",
    "\n",
    "    # LAYER 1: Maintain resolution, basic feature extraction\n",
    "    {\n",
    "        'channels': 16, \n",
    "        'up_kernel_size': 1,     # 1x1 conv (efficient channel adjustment)\n",
    "        'mid_channels': 16,\n",
    "        'num_blocks': 1,\n",
    "        'block_type': 'sew',\n",
    "        'k_pool': 1,             # No pooling\n",
    "        'stride_1': 1,\n",
    "        'stride_2': 1\n",
    "    },\n",
    "\n",
    "    # LAYER 2: Increase capacity + downsample\n",
    "    {\n",
    "        'channels': 24, \n",
    "        'up_kernel_size': 1,\n",
    "        'mid_channels': 24,\n",
    "        'num_blocks': 1,\n",
    "        'block_type': 'sew',\n",
    "        'k_pool': 2,             # /2 spatial reduction\n",
    "        'stride_1': 1,\n",
    "        'stride_2': 1\n",
    "    },\n",
    "\n",
    "    # LAYER 3: Further increase capacity + downsample\n",
    "    {\n",
    "        'channels': 32, \n",
    "        'up_kernel_size': 1,\n",
    "        'mid_channels': 32,\n",
    "        'num_blocks': 1,\n",
    "        'block_type': 'sew',\n",
    "        'k_pool': 2,             # /2 spatial reduction\n",
    "        'stride_1': 1,\n",
    "        'stride_2': 1\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Plain Architecture (No Residual Connections)\n",
    "# ============================================================================\n",
    "layer_list_plain = [\n",
    "    # STEM: Early downsampling\n",
    "    {\n",
    "        'channels': 16, \n",
    "        'up_kernel_size': 3,\n",
    "        'mid_channels': 16,\n",
    "        'num_blocks': 1,\n",
    "        'block_type': 'plain',\n",
    "        'k_pool': 2,\n",
    "        'stride_1': 2,\n",
    "        'stride_2': 1\n",
    "    },\n",
    "\n",
    "    # LAYER 1: Minimal expansion\n",
    "    {\n",
    "        'channels': 16, \n",
    "        'up_kernel_size': 1,\n",
    "        'mid_channels': 16,\n",
    "        'num_blocks': 1,\n",
    "        'block_type': 'plain',\n",
    "        'k_pool': 1,\n",
    "        'stride_1': 1,\n",
    "        'stride_2': 1\n",
    "    },\n",
    "\n",
    "    # LAYER 2: Modest capacity increase\n",
    "    {\n",
    "        'channels': 24, \n",
    "        'up_kernel_size': 1,\n",
    "        'mid_channels': 24,\n",
    "        'num_blocks': 1,\n",
    "        'block_type': 'plain',\n",
    "        'k_pool': 2,\n",
    "        'stride_1': 1,\n",
    "        'stride_2': 1\n",
    "    },\n",
    "\n",
    "    # LAYER 3: Final expansion\n",
    "    {\n",
    "        'channels': 32, \n",
    "        'up_kernel_size': 1,\n",
    "        'mid_channels': 32,\n",
    "        'num_blocks': 1,\n",
    "        'block_type': 'plain',\n",
    "        'k_pool': 2,\n",
    "        'stride_1': 1,\n",
    "        'stride_2': 1\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Spiking ResNet Architecture\n",
    "# ============================================================================\n",
    "layer_list_spiking = [\n",
    "    # STEM: Strong early downsampling\n",
    "    {\n",
    "        'channels': 16, \n",
    "        'up_kernel_size': 3,\n",
    "        'mid_channels': 16,\n",
    "        'num_blocks': 1,\n",
    "        'block_type': 'spiking',\n",
    "        'k_pool': 2,\n",
    "        'stride_1': 2,\n",
    "        'stride_2': 1\n",
    "    },\n",
    "\n",
    "    # LAYER 1: Basic blocks\n",
    "    {\n",
    "        'channels': 16, \n",
    "        'up_kernel_size': 1,\n",
    "        'mid_channels': 16,\n",
    "        'num_blocks': 1,\n",
    "        'block_type': 'spiking',\n",
    "        'k_pool': 1,\n",
    "        'stride_1': 1,\n",
    "        'stride_2': 1\n",
    "    },\n",
    "\n",
    "    # LAYER 2: Gentle downsampling\n",
    "    {\n",
    "        'channels': 24, \n",
    "        'up_kernel_size': 1,\n",
    "        'mid_channels': 24,\n",
    "        'num_blocks': 1,\n",
    "        'block_type': 'spiking',\n",
    "        'k_pool': 2,\n",
    "        'stride_1': 1,\n",
    "        'stride_2': 1\n",
    "    },\n",
    "\n",
    "    # LAYER 3: Final expansion\n",
    "    {\n",
    "        'channels': 32, \n",
    "        'up_kernel_size': 1,\n",
    "        'mid_channels': 32,\n",
    "        'num_blocks': 1,\n",
    "        'block_type': 'spiking',\n",
    "        'k_pool': 2,\n",
    "        'stride_1': 1,\n",
    "        'stride_2': 1\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2558c92",
   "metadata": {
    "id": "c2558c92"
   },
   "source": [
    "### Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636656d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "636656d5",
    "outputId": "3cbd5bf7-7ae1-4639-aad0-659dad1d2311"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Model Hyperparameters and Configuration\n",
    "# ============================================================================\n",
    "\n",
    "# Weights & Biases logging\n",
    "use_wandb = True\n",
    "wandb_name = \"snn-pendulum-IMU-colab\"\n",
    "\n",
    "# Select architecture type\n",
    "block_type = 'SEW'  # Options: 'SEW', 'plain', 'spiking'\n",
    "\n",
    "hidden = 512     # Hidden layer size\n",
    "\n",
    "# Neuron reset type\n",
    "reset_type = 'soft'  # options: 'hard' or 'soft' reset for LIF neurons\n",
    "\n",
    "surrogate_function = surrogate.ATan()  # Gradient surrogate (arctan)\n",
    "Plif = False                          # Use standard LIF (not parametric)\n",
    "tau = 2.0                             # Time constant for hidden neurons\n",
    "final_tau = 20.0                      # Time constant for output neuron\n",
    "\n",
    "norm_type = 'BN'        # Normalization type: 'BN', 'RMS', 'MUL', or None\n",
    "learnable_norm = True   # Whether normalization parameters are learnable\n",
    "init_scale = 5.0        # Initial scale for Multiplication layers\n",
    "\n",
    "K = 10           # TBPTT truncation window (backprop every K timesteps)\n",
    "transient = 0  # Initial timesteps to skip (warmup for recurrent states)\n",
    "\n",
    "num_epochs = 30  # Total training epochs\n",
    "\n",
    "early_stop_patience = 10  # Stop if no improvement for this many epochs\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \\\n",
    "         torch.device(\"mps\") if torch.backends.mps.is_available() else \\\n",
    "         torch.device(\"cpu\")\n",
    "\n",
    "# ============================================================================\n",
    "# Model initialization\n",
    "# ============================================================================\n",
    "# Map block type to layer configuration\n",
    "if block_type.lower() == 'sew':\n",
    "    layer_list = layer_list_sew\n",
    "elif block_type.lower() == 'plain':\n",
    "    layer_list = layer_list_plain\n",
    "elif block_type.lower() == 'spiking':\n",
    "    layer_list = layer_list_spiking\n",
    "\n",
    "if reset_type == 'hard':\n",
    "    v_reset = 0.0\n",
    "elif reset_type == 'soft':\n",
    "    v_reset = None\n",
    "    \n",
    "model = SNN_Net(\n",
    "    tau=tau, \n",
    "    final_tau=final_tau,\n",
    "    layer_list=layer_list, \n",
    "    hidden=hidden, \n",
    "    surrogate_function=surrogate_function,\n",
    "    connect_f=\"ADD\",  # Connection function for SEW blocks\n",
    "    Plif=Plif, \n",
    "    norm_type=norm_type, \n",
    "    learnable_norm=learnable_norm,\n",
    "    init_scale = init_scale\n",
    ").to(device)\n",
    "\n",
    "# Count total trainable parameters\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total trainable parameters: {total_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0395f8be",
   "metadata": {
    "id": "0395f8be"
   },
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load('/content/drive/MyDrive/models/model_SEW_BN/checkpoints_IMU/best_model_weights.pth', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652e5bc1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "652e5bc1",
    "outputId": "82b95299-16d0-4be3-f39a-10d2bf423036"
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5c2f44",
   "metadata": {
    "id": "ae5c2f44"
   },
   "source": [
    "## Training Pipeline\n",
    "\n",
    "This section implements the complete training pipeline using **Truncated Backpropagation Through Time (TBPTT)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835ea4fc",
   "metadata": {
    "id": "835ea4fc"
   },
   "source": [
    "### Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341e0778",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "id": "341e0778",
    "outputId": "71ee4864-8e93-4b5a-f387-589de8f8006f"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Training Configuration Dictionary\n",
    "# ============================================================================\n",
    "# This dictionary contains all hyperparameters for complete reproducibility\n",
    "CONFIG = {\n",
    "    # Model architecture\n",
    "    \"block_type\": block_type,\n",
    "    \"model_name\": model.__class__.__name__,\n",
    "    \"hidden\": hidden,\n",
    "    \"tau\": tau,\n",
    "    \"final_tau\": final_tau,\n",
    "    \"surrogate_function\": surrogate_function.__class__.__name__,\n",
    "    \"Plif\": Plif,\n",
    "    \"norm_type\": norm_type,\n",
    "    \"learnable_norm\": learnable_norm,\n",
    "    \"init_scale\": init_scale,\n",
    "\n",
    "    # TBPTT parameters\n",
    "    \"K\": K,                     \n",
    "    \"transient\": transient,        \n",
    "    \"batch_size\": BATCH_SIZE,        \n",
    "    \"sequence_length\": SEQ_LENGTH,  \n",
    "\n",
    "    # Optimizer configuration\n",
    "    # \"optimizer\": \"SGD\",\n",
    "    # \"learning_rate\": 1e-2,\n",
    "    # \"momentum\": 0.9,\n",
    "    # \"weight_decay\": 0.0,\n",
    "\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"weight_decay\": 0.0,\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    \"scheduler\": \"ReduceLROnPlateau\",\n",
    "    \"scheduler_factor\": 0.5,         \n",
    "    \"scheduler_patience\": 1,         \n",
    "    \"min_lr\": 1e-6,                  \n",
    "\n",
    "    # Training loop\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"device\": str(device),\n",
    "\n",
    "    # Early stopping\n",
    "    \"early_stop_patience\": early_stop_patience,\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# Create output directory for checkpoints and logs\n",
    "# ============================================================================\n",
    "output_dir = Path(f\"./models/model_{CONFIG['block_type']}_{CONFIG['norm_type']}/checkpoints/snn_IMU\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save configuration to JSON file\n",
    "with open(output_dir / \"config.json\", \"w\") as f:\n",
    "    json.dump(CONFIG, f, indent=4)\n",
    "\n",
    "print(f\"Configuration saved to: {output_dir / 'config.json'}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Initialize Weights & Biases\n",
    "# ============================================================================\n",
    "if use_wandb:\n",
    "\n",
    "    # Automatic run name:\n",
    "    run_name = f\"{CONFIG['block_type']}_final_tau={CONFIG['final_tau']}_tau={CONFIG['tau']}_norm={CONFIG['norm_type']}_plif={CONFIG['Plif']}_hidden={CONFIG['hidden']}\"\n",
    "\n",
    "    wandb.init(\n",
    "        project=wandb_name,\n",
    "        name=run_name,\n",
    "        config=CONFIG,\n",
    "        dir=str(output_dir)  # Save W&B files in output directory\n",
    "    )\n",
    "    \n",
    "    # Watch model for gradient and parameter tracking\n",
    "    wandb.watch(model, log=\"all\", log_freq=100)\n",
    "    print(\"W&B initialized successfully\")\n",
    "    print(f\"Run name: {run_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb15da2",
   "metadata": {
    "id": "8bb15da2"
   },
   "source": [
    "### Optimizer and Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac60795",
   "metadata": {
    "id": "eac60795"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Optimizer Setup\n",
    "# ============================================================================\n",
    "if CONFIG[\"optimizer\"] == \"SGD\":\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=CONFIG[\"learning_rate\"],\n",
    "        momentum=CONFIG[\"momentum\"],\n",
    "        weight_decay=CONFIG[\"weight_decay\"]\n",
    "    )\n",
    "elif CONFIG[\"optimizer\"] == \"Adam\":\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=CONFIG[\"learning_rate\"],\n",
    "        weight_decay=CONFIG[\"weight_decay\"]\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"Unknown optimizer: {CONFIG['optimizer']}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Loss Function\n",
    "# ============================================================================\n",
    "# Mean Squared Error for regression\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# ============================================================================\n",
    "# Learning Rate Scheduler\n",
    "# ============================================================================\n",
    "if CONFIG[\"scheduler\"] == \"ReduceLROnPlateau\":\n",
    "    # Reduce LR when validation loss plateaus\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',                          \n",
    "        factor=CONFIG[\"scheduler_factor\"],  \n",
    "        patience=CONFIG[\"scheduler_patience\"],\n",
    "        min_lr=CONFIG[\"min_lr\"]              \n",
    "    )\n",
    "elif CONFIG[\"scheduler\"] == \"CosineAnnealing\":\n",
    "    # Cosine annealing schedule\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=CONFIG[\"num_epochs\"]\n",
    "    )\n",
    "else:\n",
    "    scheduler = None\n",
    "\n",
    "print(\"Optimizer and scheduler configured successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7c7ed6",
   "metadata": {
    "id": "5d7c7ed6"
   },
   "source": [
    "### Validation Function\n",
    "\n",
    "Evaluates model performance on the validation set without gradient computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5268e1a9",
   "metadata": {
    "id": "5268e1a9"
   },
   "outputs": [],
   "source": [
    "def validate(model, val_loader, device, transient=200, fps = 100):\n",
    "    \"\"\"\n",
    "    Validation loop - evaluates model without gradient computation.\n",
    "    \n",
    "    This function is called during training to assess model performance\n",
    "    on unseen validation data. Unlike training, no weight updates occur.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set to evaluation mode\n",
    "\n",
    "    # Loss functions\n",
    "    loss_function_mse = torch.nn.MSELoss()\n",
    "    loss_function_l1 = torch.nn.L1Loss()\n",
    "\n",
    "    # Accumulators for metrics\n",
    "    val_loss_mse_total = 0.0\n",
    "    val_loss_l1_total = 0.0\n",
    "    val_rel_err_total = 0.0\n",
    "    iter_count = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        pbar_val = tqdm(iter(val_loader), desc=\"  Validation\", leave=False)\n",
    "\n",
    "        for data, targets in pbar_val:\n",
    "            iter_count += 1\n",
    "            data = data.to(device)        # [T, B, C, H, W]\n",
    "\n",
    "            targets = normalize_targets(targets.to(device)) # Normalize targets\n",
    "\n",
    "            num_steps = data.size(0)  # T (sequence length)\n",
    "\n",
    "            # Reset all neuron states at the start of each sequence\n",
    "            functional.reset_net(model)\n",
    "            \n",
    "            model.lif_out.v = targets[0].unsqueeze(-1)\n",
    "\n",
    "            val_mem_list = []\n",
    "\n",
    "            # Process entire validation sequence\n",
    "            for step in range(1, num_steps):\n",
    "                mem_out = model(data[step])  # Forward pass: [B, 1]\n",
    "                val_mem_list.append(mem_out)\n",
    "\n",
    "            # Stack all predictions: [T, B, 1] → [T, B]\n",
    "            batch_predictions = torch.stack(val_mem_list, dim=0)\n",
    "            batch_predictions = batch_predictions.squeeze(-1)\n",
    "\n",
    "            # Skip transient period (warmup)\n",
    "            targets_eff = targets[1:]\n",
    "\n",
    "            # Compute metrics for this batch\n",
    "            batch_loss_mse = loss_function_mse(batch_predictions, targets_eff)\n",
    "            batch_loss_l1 = loss_function_l1(batch_predictions, targets_eff)\n",
    "            batch_rel_err = torch.linalg.norm(batch_predictions - targets_eff) / torch.linalg.norm(targets_eff)\n",
    "\n",
    "            val_loss_mse_total += batch_loss_mse.item()\n",
    "            val_loss_l1_total += batch_loss_l1.item()\n",
    "            val_rel_err_total += batch_rel_err.item()\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar_val.set_postfix({\n",
    "                'mse': f'{batch_loss_mse.item():.6f}',\n",
    "                'l1': f'{batch_loss_l1.item():.6f}'\n",
    "            })\n",
    "\n",
    "        pbar_val.close()\n",
    "\n",
    "    # Compute average metrics across all validation batches\n",
    "    avg_val_loss_mse = val_loss_mse_total / iter_count\n",
    "    avg_val_loss_l1 = val_loss_l1_total / iter_count\n",
    "    avg_val_rel_err = val_rel_err_total / iter_count\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Validation Summary:\")\n",
    "    print(f\"{'Average MSE:':<{20}}{avg_val_loss_mse:.6f}\")\n",
    "    print(f\"{'Average L1:':<{20}}{avg_val_loss_l1:.6f}\")\n",
    "    print(f\"{'Average Rel. Err.:':<{20}}{avg_val_rel_err:.6f}\")\n",
    "    print(f\"{'Total batches:':<{20}}{iter_count}\")\n",
    "    print(f\"{'='*50}\\n\")\n",
    "\n",
    "    return {\n",
    "        'mse': avg_val_loss_mse,\n",
    "        'l1': avg_val_loss_l1,\n",
    "        'rel_err': avg_val_rel_err\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00219976",
   "metadata": {
    "id": "00219976"
   },
   "source": [
    "### Main Training Loop with TBPTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c52cc8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1c52cc8",
    "outputId": "8a9214d5-ec39-4d27-dd27-54a13abf06f7"
   },
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Starting TBPTT training\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  Total sequence length: {len(train_dataset)} timesteps\")\n",
    "print(f\"  TBPTT window size (K): {K}\")\n",
    "print(f\"  Number of epochs: {num_epochs}\")\n",
    "print(f\"  Optimizer: {CONFIG['optimizer']}\")\n",
    "print(f\"  Learning rate: {CONFIG['learning_rate']}\")\n",
    "print(f\"  Device: {device}\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# History tracking\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss_mse': [],\n",
    "    'val_loss_l1': [],\n",
    "    'val_rel_err': [],\n",
    "    'learning_rate': [],\n",
    "    'best_epoch': 0\n",
    "}\n",
    "\n",
    "# Best model tracking\n",
    "best_val_loss = float('inf')\n",
    "best_epoch = 0\n",
    "patience_counter = 0\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN TRAINING LOOP\n",
    "# ============================================================================\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"\\n{'─'*70}\")\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | LR: {current_lr:.2e}\")\n",
    "    print(f\"{'─'*70}\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # TRAINING PHASE\n",
    "    # ========================================================================\n",
    "    model.train()  # Training mode\n",
    "    epoch_loss = 0.0\n",
    "    total_chunks = 0\n",
    "\n",
    "    pbar_train = tqdm(iter(trainloader), desc=f\"  Training\", leave=True)\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(pbar_train):\n",
    "        data = data.to(device)\n",
    "        targets = normalize_targets(targets.to(device))  # Normalize targets\n",
    "\n",
    "        num_steps = data.size(0)\n",
    "\n",
    "        # Reset hidden states at start of sequence\n",
    "        functional.reset_net(model)\n",
    "        \n",
    "        model.lif_out.v = targets[0].unsqueeze(-1)\n",
    "\n",
    "        step_trunc = 0\n",
    "        K_count = 0\n",
    "        mem_rec_trunc = []\n",
    "        batch_loss = 0.0\n",
    "        batch_chunks = 0\n",
    "\n",
    "        # Process through entire sequence with TBPTT\n",
    "        for step in range(1, num_steps):\n",
    "            mem_out = model(data[step])\n",
    "            mem_rec_trunc.append(mem_out)\n",
    "            step_trunc += 1\n",
    "\n",
    "            # Backward pass every K steps\n",
    "            if step_trunc == K:\n",
    "                mem_rec_trunc = torch.stack(mem_rec_trunc, dim=0)\n",
    "                \n",
    "                start_idx = int(K_count * K) + 1  # <--- DESPLAZAMIENTO +1\n",
    "                end_idx = start_idx + K\n",
    "                \n",
    "                target_slice = targets[start_idx : end_idx]\n",
    "\n",
    "                loss = loss_fn(mem_rec_trunc.squeeze(-1), target_slice)\n",
    "\n",
    "                # Backward and optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                model.detach()  # Truncate gradients\n",
    "\n",
    "                if step >= transient:\n",
    "                    epoch_loss += loss.item()\n",
    "                    batch_loss += loss.item()\n",
    "                    total_chunks += 1\n",
    "                    batch_chunks += 1\n",
    "\n",
    "                    if use_wandb:\n",
    "                        wandb.log({\n",
    "                            \"train/chunk_loss\": loss.item(),\n",
    "                            \"train/learning_rate\": current_lr,\n",
    "                            \"train/epoch\": epoch + 1,\n",
    "                            \"train/batch\": batch_idx,\n",
    "                        })\n",
    "\n",
    "                # Reset\n",
    "                K_count += 1\n",
    "                step_trunc = 0\n",
    "                mem_rec_trunc = []\n",
    "\n",
    "            # Handle remaining timesteps\n",
    "            if (step == num_steps - 1) and (mem_rec_trunc):\n",
    "                mem_rec_trunc = torch.stack(mem_rec_trunc, dim=0)\n",
    "                \n",
    "                remaining_len = len(mem_rec_trunc)\n",
    "                start_idx = (K_count * K) + 1\n",
    "                end_idx = start_idx + remaining_len\n",
    "                \n",
    "                target_slice = targets[int(start_idx):int(end_idx)]\n",
    "\n",
    "                loss = loss_fn(mem_rec_trunc.squeeze(-1), target_slice)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                model.detach()\n",
    "\n",
    "                if step >= transient:\n",
    "                    epoch_loss += loss.item()\n",
    "                    batch_loss += loss.item()\n",
    "                    total_chunks += 1\n",
    "                    batch_chunks += 1\n",
    "\n",
    "                    if use_wandb:\n",
    "                        wandb.log({\n",
    "                            \"train/chunk_loss\": loss.item(),\n",
    "                            \"train/learning_rate\": current_lr,\n",
    "                            \"train/epoch\": epoch + 1,\n",
    "                            \"train/batch\": batch_idx,\n",
    "                        })\n",
    "\n",
    "        # Update progress bar\n",
    "        avg_batch_loss = batch_loss / max(1, batch_chunks)\n",
    "        pbar_train.set_postfix({'loss': f'{avg_batch_loss:.6f}'})\n",
    "\n",
    "    pbar_train.close()\n",
    "\n",
    "    # ========================================================================\n",
    "    # COMPUTE EPOCH METRICS\n",
    "    # ========================================================================\n",
    "    avg_train_loss = epoch_loss / max(1, total_chunks)\n",
    "\n",
    "    # ========================================================================\n",
    "    # VALIDATION PHASE\n",
    "    # ========================================================================\n",
    "    val_metrics = val_metrics = validate(model, valloader, device, transient)\n",
    "    avg_val_loss_mse = val_metrics['mse']\n",
    "    avg_val_loss_l1 = val_metrics['l1']\n",
    "    avg_val_rel_err = val_metrics['rel_err']\n",
    "\n",
    "    # ========================================================================\n",
    "    # UPDATE HISTORY\n",
    "    # ========================================================================\n",
    "    history['train_loss'].append(avg_train_loss)\n",
    "    history['val_loss_mse'].append(avg_val_loss_mse)\n",
    "    history['val_loss_l1'].append(avg_val_loss_l1)\n",
    "    history['val_rel_err'].append(avg_val_rel_err)\n",
    "    history['learning_rate'].append(current_lr)\n",
    "\n",
    "    # ========================================================================\n",
    "    # PRINT EPOCH SUMMARY\n",
    "    # ========================================================================\n",
    "    print(f\"  Train Loss (MSE): {avg_train_loss:.6f}\")\n",
    "    print(f\"  Val Loss (MSE):   {avg_val_loss_mse:.6f}\")\n",
    "    print(f\"  Val Loss (L1):    {avg_val_loss_l1:.6f}\")\n",
    "    print(f\"  Val Rel Error:    {avg_val_rel_err:.6f}\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # LOG TO WANDB\n",
    "    # ========================================================================\n",
    "    if use_wandb:\n",
    "        wandb.log({\n",
    "            \"epoch/train_loss\": avg_train_loss,\n",
    "            \"epoch/val_loss_mse\": avg_val_loss_mse,\n",
    "            \"epoch/val_loss_l1\": avg_val_loss_l1,\n",
    "            \"epoch/val_rel_err\": avg_val_rel_err,\n",
    "            \"epoch/learning_rate\": current_lr,\n",
    "            \"epoch/number\": epoch + 1,\n",
    "        })\n",
    "    # ========================================================================\n",
    "    # SAVE CHECKPOINTS\n",
    "    # ========================================================================\n",
    "\n",
    "    # 1. ALWAYS save latest checkpoint (to resume training)\n",
    "    checkpoint_latest = {\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "        'train_loss': avg_train_loss,\n",
    "        'val_loss_mse': avg_val_loss_mse,\n",
    "        'val_loss_l1': avg_val_loss_l1,\n",
    "        'val_rel_err': avg_val_rel_err,\n",
    "        'history': history,\n",
    "        'config': CONFIG,\n",
    "    }\n",
    "    torch.save(checkpoint_latest, output_dir / \"checkpoint_latest.pth\")\n",
    "\n",
    "    # 2. Save BEST model (based on validation MSE loss - same as training)\n",
    "    if avg_val_loss_mse < best_val_loss:\n",
    "        best_val_loss = avg_val_loss_mse\n",
    "        best_epoch = epoch + 1\n",
    "        history['best_epoch'] = best_epoch\n",
    "        patience_counter = 0  # Reset patience\n",
    "\n",
    "        torch.save(checkpoint_latest, output_dir / \"checkpoint_best.pth\")\n",
    "        # Also save just the model weights (lighter file)\n",
    "        torch.save(model.state_dict(), output_dir / \"best_model_weights.pth\")\n",
    "\n",
    "        print(f\"  New best model saved. Val MSE: {best_val_loss:.6f}\")\n",
    "\n",
    "        if use_wandb:\n",
    "            wandb.run.summary[\"best_val_loss_mse\"] = best_val_loss\n",
    "            wandb.run.summary[\"best_epoch\"] = best_epoch\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"  No improvement ({patience_counter}/{early_stop_patience})\")\n",
    "\n",
    "    # 3. Save periodic checkpoints (every 10 epochs)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save(checkpoint_latest, output_dir / f\"checkpoint_epoch_{epoch+1}.pth\")\n",
    "        print(f\"  Periodic checkpoint saved (epoch {epoch+1})\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # LEARNING RATE SCHEDULING\n",
    "    # ========================================================================\n",
    "    if scheduler:\n",
    "        if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss_mse)  # Use validation MSE loss\n",
    "        else:\n",
    "            scheduler.step()  # Use epoch number\n",
    "\n",
    "    # ========================================================================\n",
    "    # EARLY STOPPING CHECK\n",
    "    # ========================================================================\n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Early stopping triggered. No improvement for {early_stop_patience} epochs\")\n",
    "        print(f\"{'='*70}\")\n",
    "        break\n",
    "# ============================================================================\n",
    "# TRAINING FINISHED\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Training completed\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  Best epoch: {best_epoch}\")\n",
    "print(f\"  Best val MSE loss: {best_val_loss:.6f}\")\n",
    "print(f\"  Final train loss: {history['train_loss'][-1]:.6f}\")\n",
    "print(f\"  Final val MSE loss: {history['val_loss_mse'][-1]:.6f}\")\n",
    "print(f\"  Final val L1 loss: {history['val_loss_l1'][-1]:.6f}\")\n",
    "print(f\"  Final val rel error: {history['val_rel_err'][-1]:.6f}\")\n",
    "print(f\"  Checkpoints saved in: {output_dir}\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Save final history\n",
    "with open(output_dir / \"training_history.json\", \"w\") as f:\n",
    "    json.dump(history, f, indent=4)\n",
    "\n",
    "if use_wandb:\n",
    "    # Save history as artifact\n",
    "    artifact = wandb.Artifact('training_history', type='history')\n",
    "    artifact.add_file(str(output_dir / \"training_history.json\"))\n",
    "    wandb.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a9b6e8",
   "metadata": {
    "id": "99a9b6e8"
   },
   "source": [
    "## Test Evaluation with Continuous Data\n",
    "\n",
    "This section evaluates the trained model on the held-out test set using the **continuous sequence** (not split into chunks)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428df0b8",
   "metadata": {
    "id": "428df0b8"
   },
   "source": [
    "### Examining Normalization Layer Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138fbfd7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "138fbfd7",
    "outputId": "5063cd0f-6b50-413c-869b-6a1c79ebd5ee"
   },
   "outputs": [],
   "source": [
    "# Compute mean weight/bias per layer, then overall network mean/std\n",
    "\n",
    "weight_means = []  # Mean weight per layer\n",
    "bias_means = []    # Mean bias per layer (if present)\n",
    "\n",
    "for layer in model.modules():\n",
    "    # Check if the layer is BatchNorm2d, RMSNorm2d, or MultiplyBy\n",
    "    is_norm_layer = isinstance(layer, (nn.BatchNorm2d, RMSNorm2d, MultiplyBy))\n",
    "    \n",
    "    if is_norm_layer:\n",
    "        layer_name = layer.__class__.__name__\n",
    "        line_parts = [f\"Layer: {layer_name}\"]\n",
    "        \n",
    "        if hasattr(layer, 'weight') and layer.weight is not None:\n",
    "            if hasattr(layer.weight, 'data'):  # Learnable (tensor)\n",
    "                weight_mean = layer.weight.data.mean().item()\n",
    "            else:  # Fixed (float)\n",
    "                weight_mean = float(layer.weight)\n",
    "            \n",
    "            weight_means.append(weight_mean)\n",
    "            line_parts.append(f\"Weight mean: {weight_mean:.4f}\")\n",
    "            \n",
    "            # Bias exists only in BatchNorm2d\n",
    "            if hasattr(layer, 'bias') and layer.bias is not None:\n",
    "                bias_mean = layer.bias.data.mean().item()\n",
    "                bias_means.append(bias_mean)\n",
    "                line_parts.append(f\"Bias mean: {bias_mean:.4f}\")\n",
    "        \n",
    "        print(\" | \".join(line_parts))\n",
    "\n",
    "# Compute overall network statistics\n",
    "if weight_means:\n",
    "    network_weight_mean = np.mean(weight_means)\n",
    "    network_weight_std = np.std(weight_means)\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Network weight mean: {network_weight_mean:.4f}, std: {network_weight_std:.4f}\")\n",
    "    \n",
    "if bias_means:\n",
    "    network_bias_mean = np.mean(bias_means)\n",
    "    network_bias_std = np.std(bias_means)\n",
    "    print(f\"Network bias mean: {network_bias_mean:.4f}, std: {network_bias_std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070022e3",
   "metadata": {
    "id": "070022e3"
   },
   "source": [
    "### Monitoring Configuration\n",
    "\n",
    "Configure what to monitor during test evaluation:\n",
    "\n",
    "**Options:**\n",
    "- `\"none\"`: No monitoring (fastest evaluation)\n",
    "- `\"spikes\"`: Record spike activity for all LIF layers\n",
    "- `\"norm\"`: Record normalization layer statistics\n",
    "- `\"both\"`: Full monitoring (spikes + normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac6bf64",
   "metadata": {
    "id": "1ac6bf64"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Monitoring Mode Configuration\n",
    "# ============================================================================\n",
    "monitor_mode = \"spikes\"  # Options: \"none\", \"spikes\", \"norm\", \"both\"\n",
    "\n",
    "def enable_monitoring(model, mode):\n",
    "    \"\"\"Enable monitoring hooks based on selected mode.\"\"\"\n",
    "    if mode in [\"spikes\", \"both\"]:\n",
    "        model.enable_spike_recording()\n",
    "    if mode in [\"norm\", \"both\"]:\n",
    "        model.enable_norm_monitoring()\n",
    "\n",
    "\n",
    "def disable_monitoring(model, mode):\n",
    "    \"\"\"Disable monitoring hooks and clean up.\"\"\"\n",
    "    if mode in [\"spikes\", \"both\"]:\n",
    "        model.disable_spike_recording()\n",
    "    if mode in [\"norm\", \"both\"]:\n",
    "        model.disable_norm_monitoring()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e49559b",
   "metadata": {
    "id": "8e49559b"
   },
   "source": [
    "### Test Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b2fe62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "66b2fe62",
    "outputId": "af180c14-27d3-46f2-a3f9-701409401738"
   },
   "outputs": [],
   "source": [
    "# Evaluation on test set\n",
    "loss_function = torch.nn.MSELoss()\n",
    "\n",
    "spike_activity_over_time = {} if monitor_mode in [\"spikes\", \"both\"] else None\n",
    "norm_activity_over_time = {} if monitor_mode in [\"norm\", \"both\"] else None\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    enable_monitoring(model, monitor_mode)\n",
    "\n",
    "    print(f\"\\nEvaluating model on test set...\")\n",
    "\n",
    "    test_loss_total = 0.0\n",
    "    test_rel_err_total = 0.0\n",
    "    iter_count = 0\n",
    "\n",
    "    # Store all predictions for visualization\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    # Progress bar for test batches\n",
    "    pbar_test = tqdm(testloader, desc=\"  Test batches\", leave=True)\n",
    "\n",
    "    for data, targets in pbar_test:\n",
    "        iter_count += 1\n",
    "        data = data.to(device)           # [T, B, C, H, W]\n",
    "        targets = normalize_targets(targets.to(device)) # Normalize targets\n",
    "\n",
    "        num_steps = data.size(0)  # T\n",
    "\n",
    "        # Reset hidden states at start of each sequence batch\n",
    "        functional.reset_net(model)\n",
    "        \n",
    "        model.lif_out.v = targets[0].unsqueeze(-1)\n",
    "\n",
    "        test_mem_list = []\n",
    "\n",
    "        # Process through entire test sequence\n",
    "        for step in range(1, num_steps):\n",
    "\n",
    "            # Forward pass\n",
    "            mem_out = model(data[step])  # [B, 1]\n",
    "            test_mem_list.append(mem_out)\n",
    "\n",
    "            # Initialize tracking lists on the first timestep\n",
    "            if step == 1:\n",
    "                if monitor_mode in [\"spikes\", \"both\"]:\n",
    "                    for k in model.spike_record.keys():\n",
    "                        spike_activity_over_time[k] = []\n",
    "\n",
    "                if monitor_mode in [\"norm\", \"both\"]:\n",
    "                    for k in model.norm_stats.keys():\n",
    "                        norm_activity_over_time[k] = {\n",
    "                            'input_mean': [],\n",
    "                            'input_std': [],\n",
    "                            'output_mean': [],\n",
    "                            'output_std': [],\n",
    "                            'input_range': [],\n",
    "                            'output_range': []\n",
    "                        }\n",
    "\n",
    "            if monitor_mode in [\"spikes\", \"both\"]:\n",
    "                # For each LIF layer, compute spike activity for this timestep\n",
    "                for k, v in model.spike_record.items():\n",
    "                    # v: [B, C, H, W] or [B, N]\n",
    "                    # Average spikes per neuron in this layer at this timestep\n",
    "                    activity = v.detach().cpu().mean().item()\n",
    "                    spike_activity_over_time[k].append(activity)\n",
    "\n",
    "            if monitor_mode in [\"norm\", \"both\"]:\n",
    "                # Para cada capa BatchNorm, extraer estadísticas en este timestep\n",
    "                for layer_name, stats in model.norm_stats.items():\n",
    "                    # Promedio sobre todos los canales para este timestep\n",
    "                    norm_activity_over_time[layer_name]['input_mean'].append(\n",
    "                        np.mean(stats['input_mean_per_channel'])\n",
    "                    )\n",
    "                    norm_activity_over_time[layer_name]['input_std'].append(\n",
    "                        np.mean(stats['input_std_per_channel'])\n",
    "                    )\n",
    "                    norm_activity_over_time[layer_name]['output_mean'].append(\n",
    "                        np.mean(stats['output_mean_per_channel'])\n",
    "                    )\n",
    "                    norm_activity_over_time[layer_name]['output_std'].append(\n",
    "                        np.mean(stats['output_std_per_channel'])\n",
    "                    )\n",
    "\n",
    "                    # Rangos (max - min) promediados\n",
    "                    input_range = np.mean(stats['input_max_per_channel'] - stats['input_min_per_channel'])\n",
    "                    output_range = np.mean(stats['output_max_per_channel'] - stats['output_min_per_channel'])\n",
    "\n",
    "                    norm_activity_over_time[layer_name]['input_range'].append(input_range)\n",
    "                    norm_activity_over_time[layer_name]['output_range'].append(output_range)\n",
    "\n",
    "        # Stack all predictions for this batch\n",
    "        batch_predictions = torch.stack(test_mem_list, dim=0)  # [T, B, 1]\n",
    "        batch_predictions = batch_predictions.squeeze(-1)  # [T, B]\n",
    "        \n",
    "        targets_eff = targets[1:]\n",
    "\n",
    "        # Calculate metrics for this batch\n",
    "        batch_loss = loss_function(batch_predictions, targets_eff)\n",
    "        batch_rel_err = torch.linalg.norm(batch_predictions - targets_eff) / torch.linalg.norm(targets_eff)\n",
    "\n",
    "        test_loss_total += batch_loss.item()\n",
    "        test_rel_err_total += batch_rel_err.item()\n",
    "\n",
    "        # Update progress bar\n",
    "        pbar_test.set_postfix({'loss': f'{batch_loss.item():.6f}'})\n",
    "\n",
    "        # Store for visualization (flatten batch dimension)\n",
    "        all_predictions.append(batch_predictions.detach().cpu().numpy())\n",
    "        all_targets.append(targets_eff.detach().cpu().numpy())\n",
    "\n",
    "    pbar_test.close()\n",
    "\n",
    "    # Average metrics\n",
    "    avg_test_loss = test_loss_total / iter_count\n",
    "    avg_test_rel_err = test_rel_err_total / iter_count\n",
    "\n",
    "    # Concatenate all predictions (flatten across batches and batch dimension)\n",
    "    test_mem_continuous = np.concatenate([p.reshape(-1) for p in all_predictions])\n",
    "    test_target_continuous = np.concatenate([t.reshape(-1) for t in all_targets])\n",
    "\n",
    "disable_monitoring(model, monitor_mode)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"{'Test L1-loss:':<{20}}{avg_test_loss:1.2e}\")\n",
    "print(f\"{'Test rel. err.:':<{20}}{avg_test_rel_err:1.2e}\")\n",
    "print(f\"{'Total iterations:':<{20}}{iter_count}\")\n",
    "print(f\"{'Total timesteps:':<{20}}{len(test_mem_continuous)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0594f319",
   "metadata": {
    "id": "0594f319"
   },
   "source": [
    "### Spike Activity Analysis\n",
    "\n",
    "Analyzes spike activity across the network during test evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cc8d2a",
   "metadata": {
    "id": "b3cc8d2a"
   },
   "outputs": [],
   "source": [
    "n_plots = 2\n",
    "\n",
    "if monitor_mode in [\"spikes\", \"both\"]:\n",
    "\n",
    "    # Convert to arrays to calculate averages across the network\n",
    "    all_layers = list(spike_activity_over_time.keys())\n",
    "    T = len(next(iter(spike_activity_over_time.values())))  # number of timesteps\n",
    "\n",
    "    # Average spike activity per timestep across the network\n",
    "    spike_activity_total = np.zeros(T)\n",
    "    for k in all_layers:\n",
    "        spike_activity_total += spike_activity_over_time[k]\n",
    "    spike_activity_total /= len(all_layers)\n",
    "\n",
    "    # data: [T, B, C, H, W]\n",
    "    num_timesteps = data.size(0)\n",
    "    num_events_per_timestep = []\n",
    "\n",
    "    for t in range(num_timesteps):\n",
    "        # Count non-zero values at this timestep (sum over batch, channels, height, width)\n",
    "        events = (data[t] != 0).sum().item()\n",
    "        num_events_per_timestep.append(events)\n",
    "\n",
    "    num_events_per_timestep = np.array(num_events_per_timestep)\n",
    "\n",
    "    n_plots = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d8300b",
   "metadata": {
    "id": "14d8300b"
   },
   "source": [
    "### Prediction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dda2f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "05dda2f5",
    "outputId": "ef508cc9-9ba1-46c9-a5da-1c4d74fe5738"
   },
   "outputs": [],
   "source": [
    "# Continuous results visualization\n",
    "fig, axes = plt.subplots(n_plots, 1, figsize=(n_plots*3, n_plots*3))  # 4 subplots\n",
    "\n",
    "# Plot a longer window to see continuous behavior\n",
    "window_start = 0\n",
    "window_end = min(30000, len(test_mem_continuous))\n",
    "\n",
    "# Subplot 1: Model output vs target\n",
    "axes[0].plot(denormalize_targets(test_mem_continuous[window_start:window_end]), label=\"Model Output\", alpha=0.8, linewidth=1.5)\n",
    "axes[0].plot(denormalize_targets(test_target_continuous[window_start:window_end]), label=\"Target\", alpha=0.8, linewidth=1.5)\n",
    "axes[0].set_xlabel(\"Frame\")\n",
    "axes[0].set_ylabel(\"Angle (degrees)\")\n",
    "axes[0].set_title(\"Model Output vs Target (Continuous Evaluation)\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Absolute error\n",
    "test_error = np.abs(denormalize_targets(test_mem_continuous[window_start:window_end]) - denormalize_targets(test_target_continuous[window_start:window_end]))\n",
    "axes[1].plot(test_error[window_start:window_end], color='orange', linewidth=1)\n",
    "axes[1].set_xlabel(\"Frame\")\n",
    "axes[1].set_ylabel(\"Absolute Error (degrees)\")\n",
    "axes[1].set_title(\"Absolute Error over Time\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "if monitor_mode in [\"spikes\", \"both\"]:\n",
    "    # Subplot 3: Average spike activity\n",
    "    axes[2].plot(spike_activity_total[window_start:window_end], color='green', linewidth=1.5)\n",
    "    axes[2].set_xlabel(\"Frame\")\n",
    "    axes[2].set_ylabel(\"Average Spike Activity\")\n",
    "    axes[2].set_title(\"Average Spike Activity Across the Network Over Time\")\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "    # Subplot 4: Number of input events\n",
    "    axes[3].plot(num_events_per_timestep[window_start:window_end], color='purple', linewidth=1.5)\n",
    "    axes[3].set_xlabel(\"Frame\")\n",
    "    axes[3].set_ylabel(\"Number of Events\")\n",
    "    axes[3].set_title(\"Number of Input Events per Timestep\")\n",
    "    axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "    print(\"\\nSpike activity statistics (average over time):\")\n",
    "    for k in all_layers:\n",
    "        mean_spike = np.mean(spike_activity_over_time[k])\n",
    "        print(f\"  {k:20s}: {mean_spike:.4f}\")\n",
    "\n",
    "    print(f\"\\nAverage spike activity across the entire network: {np.mean(spike_activity_total):.4f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nError statistics:\")\n",
    "print(f\"  Mean error: {np.mean(np.abs(denormalize_targets(test_mem_continuous) - denormalize_targets(test_target_continuous))):.2f}°\")\n",
    "print(f\"  Std error: {np.std(np.abs(denormalize_targets(test_mem_continuous) - denormalize_targets(test_target_continuous))):.2f}°\")\n",
    "print(f\"  Max error: {np.max(np.abs(denormalize_targets(test_mem_continuous) - denormalize_targets(test_target_continuous))):.2f}°\")\n",
    "\n",
    "\n",
    "print(f\"\\nError statistics Window:\")\n",
    "print(f\"  Mean error: {np.mean(np.abs(denormalize_targets(test_mem_continuous[window_start:window_end]) - denormalize_targets(test_target_continuous[window_start:window_end]))):.2f}°\")\n",
    "print(f\"  Std error: {np.std(np.abs(denormalize_targets(test_mem_continuous[window_start:window_end]) - denormalize_targets(test_target_continuous[window_start:window_end]))):.2f}°\")\n",
    "print(f\"  Max error: {np.max(np.abs(denormalize_targets(test_mem_continuous[window_start:window_end]) - denormalize_targets(test_target_continuous[window_start:window_end]))):.2f}°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd4a503",
   "metadata": {
    "id": "efd4a503"
   },
   "source": [
    "### Normalization Statistics Analysis\n",
    "\n",
    "Analyzes how normalization layers transform activations over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44869d1b",
   "metadata": {
    "id": "44869d1b"
   },
   "outputs": [],
   "source": [
    "def plot_norm_activity_over_time(norm_activity_over_time, layer_name):\n",
    "    \"\"\"Visualize how normalization statistics evolve over time.\"\"\"\n",
    "    activity = norm_activity_over_time[layer_name]\n",
    "    timesteps = np.arange(len(activity['input_mean']))\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.suptitle(f'Activity Over Time: {layer_name}', fontsize=16)\n",
    "\n",
    "    # Plot 1: Mean evolution\n",
    "    ax = axes[0, 0]\n",
    "    ax.plot(timesteps, activity['input_mean'], '-', label='Input Mean', alpha=0.7, linewidth=2)\n",
    "    ax.plot(timesteps, activity['output_mean'], '-', label='Output Mean', alpha=0.7, linewidth=2)\n",
    "    ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    ax.set_xlabel('Timestep')\n",
    "    ax.set_ylabel('Mean')\n",
    "    ax.set_title('Mean Over Time')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot 2: Std evolution\n",
    "    ax = axes[0, 1]\n",
    "    ax.plot(timesteps, activity['input_std'], '-', label='Input Std', alpha=0.7, linewidth=2)\n",
    "    ax.plot(timesteps, activity['output_std'], '-', label='Output Std', alpha=0.7, linewidth=2)\n",
    "    ax.axhline(y=1, color='gray', linestyle='--', alpha=0.5)\n",
    "    ax.set_xlabel('Timestep')\n",
    "    ax.set_ylabel('Std')\n",
    "    ax.set_title('Std Over Time')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot 3: Range evolution\n",
    "    ax = axes[1, 0]\n",
    "    ax.plot(timesteps, activity['input_range'], '-', label='Input Range', alpha=0.7, linewidth=2)\n",
    "    ax.plot(timesteps, activity['output_range'], '-', label='Output Range', alpha=0.7, linewidth=2)\n",
    "    ax.set_xlabel('Timestep')\n",
    "    ax.set_ylabel('Range (max - min)')\n",
    "    ax.set_title('Value Range Over Time')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot 4: Actual scaling factor (output / input)\n",
    "    ax = axes[1, 1]\n",
    "\n",
    "    # Compute scaling factors\n",
    "    std_scaling = np.array(activity['output_std']) / (np.array(activity['input_std']) + 1e-8)\n",
    "    range_scaling = np.array(activity['output_range']) / (np.array(activity['input_range']) + 1e-8)\n",
    "\n",
    "    ax.plot(timesteps, std_scaling, '-', alpha=0.7, linewidth=2,\n",
    "            label='Std Scaling (out/in)', color='purple')\n",
    "    ax.plot(timesteps, range_scaling, '-', alpha=0.7, linewidth=2,\n",
    "            label='Range Scaling (out/in)', color='orange')\n",
    "    ax.axhline(y=1, color='gray', linestyle='--', alpha=0.5, label='No scaling (1x)')\n",
    "\n",
    "    # Add average line\n",
    "    avg_std_scaling = np.mean(std_scaling)\n",
    "    ax.axhline(y=avg_std_scaling, color='purple', linestyle=':', alpha=0.7, linewidth=2,\n",
    "               label=f'Avg Std Scaling: {avg_std_scaling:.1f}x')\n",
    "\n",
    "    ax.set_xlabel('Timestep')\n",
    "    ax.set_ylabel('Scaling Factor (Output / Input)')\n",
    "    ax.set_title('Amplification Factor Over Time')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim(bottom=0)  # Ensure it starts from 0\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ef1e3b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "26ef1e3b",
    "outputId": "5a0ea4e0-0df3-4edf-d3f1-67a27d620142"
   },
   "outputs": [],
   "source": [
    "if monitor_mode in [\"norm\", \"both\"]:\n",
    "    # Visualize for each BatchNorm layer\n",
    "    for layer_name in norm_activity_over_time.keys():\n",
    "        fig = plot_norm_activity_over_time(norm_activity_over_time, layer_name)\n",
    "        plt.show()\n",
    "        # Or save: fig.savefig(f'{layer_name}_temporal_analysis.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v2L4D2rabbo7",
   "metadata": {
    "id": "v2L4D2rabbo7"
   },
   "outputs": [],
   "source": [
    "def compute_mean_amplification_per_layer(norm_activity_over_time):\n",
    "    \"\"\"Compute average amplification factor (std_out / std_in) over time for each layer.\"\"\"\n",
    "    layer_names = []\n",
    "    mean_amplifications = []\n",
    "\n",
    "    for layer_name, activity in norm_activity_over_time.items():\n",
    "        input_std = np.array(activity['input_std'])\n",
    "        output_std = np.array(activity['output_std'])\n",
    "\n",
    "        std_scaling = output_std / (input_std + 1e-8)\n",
    "        mean_scaling = std_scaling.mean()\n",
    "\n",
    "        layer_names.append(layer_name)\n",
    "        mean_amplifications.append(mean_scaling)\n",
    "\n",
    "    return layer_names, np.array(mean_amplifications)\n",
    "\n",
    "def plot_network_amplification(layer_names, mean_amplifications):\n",
    "    \"\"\"Bar plot showing average amplification factor per layer.\"\"\"\n",
    "    layers = np.arange(len(layer_names))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "    ax.bar(layers, mean_amplifications, alpha=0.8, color='purple')\n",
    "    ax.axhline(1.0, color='red', linestyle='--', linewidth=2, label='No scaling (1x)')\n",
    "\n",
    "    avg_network = mean_amplifications.mean()\n",
    "    ax.axhline(avg_network, color='black', linestyle=':', linewidth=2,\n",
    "               label=f'Network avg = {avg_network:.1f}x')\n",
    "\n",
    "    ax.set_xlabel('Layer')\n",
    "    ax.set_ylabel('Mean Amplification (Output / Input)')\n",
    "    ax.set_title(f'Mean Amplification Factor per Layer (avg={avg_network:.1f}x)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5Q4V6nVGbcK6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "5Q4V6nVGbcK6",
    "outputId": "81b6e982-5623-4b55-eb9c-eb638091e0bb"
   },
   "outputs": [],
   "source": [
    "if monitor_mode in [\"norm\", \"both\"]:\n",
    "    layer_names, mean_amplifications = compute_mean_amplification_per_layer(\n",
    "        norm_activity_over_time\n",
    "    )\n",
    "\n",
    "    fig = plot_network_amplification(layer_names, mean_amplifications)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d59005",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_wandb:\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "SNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
